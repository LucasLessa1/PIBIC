{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For files e data manipulations\n",
    "from imports_ import *\n",
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnn = PreNeuralNetwork(train='C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/train', test='C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/test' ,\n",
    "                    valid='C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_train = 'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/train'\n",
    "dir_test  = 'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/test'\n",
    "dir_valid = 'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/validation'\n",
    "\n",
    "batch_size = 4  \n",
    "width = 224\n",
    "length = 224\n",
    "channel = 3\n",
    "image_size = (width, length)\n",
    "random.seed(123) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estÃ¡ dando o CLOCK_WATCHDOG_TIMEOUT reduzirei a quantidade de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77877 images belonging to 9 classes.\n",
      "Found 4328 images belonging to 9 classes.\n",
      "Found 4326 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen= ImageDataGenerator(rescale=1.0/255)\n",
    "val_datagen  = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(dir_train,\n",
    "                                        target_size=image_size,\n",
    "                                        color_mode='rgb',  # Ensure RGB color mode\n",
    "                                        class_mode='categorical',  # Adjust class_mode as needed\n",
    "                                        batch_size=batch_size,\n",
    "                                        subset='training'  # Specify 'training' for the training set\n",
    "                                    )\n",
    "\n",
    "val_generator=val_datagen.flow_from_directory(dir_valid,\n",
    "                                        target_size=image_size,\n",
    "                                        color_mode='rgb',\n",
    "                                        class_mode='categorical',\n",
    "                                        batch_size=batch_size\n",
    "                                    )\n",
    "\n",
    "test_generator=test_datagen.flow_from_directory(dir_test,\n",
    "                                        target_size=image_size,\n",
    "                                        color_mode='rgb',\n",
    "                                        class_mode='categorical',\n",
    "                                        batch_size=batch_size\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 9\n"
     ]
    }
   ],
   "source": [
    "n_classes = train_generator.num_classes\n",
    "print(\"Number of classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU is available and accessible.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a GPU with index 0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Specify GPU device\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (318676807.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    516berb\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "516berb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19470/19470 [==============================] - 4666s 240ms/step - loss: 1.1642 - accuracy: 0.6965 - val_loss: 1.1216 - val_accuracy: 0.7077\n",
      "Epoch 2/10\n",
      "19470/19470 [==============================] - 4491s 231ms/step - loss: 1.1547 - accuracy: 0.6967 - val_loss: 1.1328 - val_accuracy: 0.7077\n",
      "Epoch 3/10\n",
      "19470/19470 [==============================] - 4496s 231ms/step - loss: 1.1503 - accuracy: 0.6967 - val_loss: 1.1120 - val_accuracy: 0.7077\n",
      "Epoch 4/10\n",
      "19470/19470 [==============================] - 4596s 236ms/step - loss: 1.1475 - accuracy: 0.6967 - val_loss: 1.1111 - val_accuracy: 0.7077\n",
      "Epoch 5/10\n",
      "19470/19470 [==============================] - 4716s 242ms/step - loss: 1.1449 - accuracy: 0.6967 - val_loss: 1.1082 - val_accuracy: 0.7077\n",
      "Epoch 6/10\n",
      "19470/19470 [==============================] - 4678s 240ms/step - loss: 1.1431 - accuracy: 0.6967 - val_loss: 1.1067 - val_accuracy: 0.7077\n",
      "Epoch 7/10\n",
      "19470/19470 [==============================] - 4832s 248ms/step - loss: 1.1418 - accuracy: 0.6967 - val_loss: 1.1088 - val_accuracy: 0.7077\n",
      "Epoch 8/10\n",
      "19470/19470 [==============================] - 4842s 249ms/step - loss: 1.1395 - accuracy: 0.6967 - val_loss: 1.1033 - val_accuracy: 0.7077\n",
      "Epoch 9/10\n",
      "19470/19470 [==============================] - 4571s 235ms/step - loss: 1.1386 - accuracy: 0.6967 - val_loss: 1.1196 - val_accuracy: 0.7077\n",
      "Epoch 10/10\n",
      "19470/19470 [==============================] - 4567s 235ms/step - loss: 1.1382 - accuracy: 0.6967 - val_loss: 1.1054 - val_accuracy: 0.7077\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12736\\3248568801.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimage_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Adjust image dimensions as needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet101Model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stop_patience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12736\\2519254833.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, train_data, val_data, epochs, batch_size, early_stop_patience)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stop_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         )\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12736\\2519254833.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, history)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         ):\n\u001b[1;32m---> 40\u001b[1;33m             self.metrics_df = self.metrics_df.append({\n\u001b[0m\u001b[0;32m     41\u001b[0m                 \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucas\\PIBIC\\lessinha\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6198\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6199\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6200\u001b[0m         ):\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6202\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# Create an instance of ResNet101Model\n",
    "num_classes = n_classes  # Adjust the number of classes as needed\n",
    "image_shape = (width,length,channel)  # Adjust image dimensions as needed\n",
    "model = ResNet101Model(num_classes, image_shape)\n",
    "\n",
    "# Train the model\n",
    "history = model.train(train_generator, val_generator, epochs=1, batch_size=batch_size, early_stop_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082/1082 [==============================] - 218s 202ms/step - loss: 1.1143 - accuracy: 0.7027\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checkpoint\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(f'model_NIG-CHEST/model_vgg_{qntd_for_model}_1.h5', \n",
    "#                                                 verbose = 1, \n",
    "#                                                 save_best = True, \n",
    "#                                                 save_weights_only = True)\n",
    "\n",
    "# # Early stop\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(patience = 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lessinha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
