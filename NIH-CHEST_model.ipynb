{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For files e data manipulations\n",
    "# from neuralNetwork import *\n",
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "          \n",
    "import zipfile                \n",
    "import shutil            \n",
    "import glob         \n",
    "\n",
    "#For math operations           \n",
    "import time               \n",
    "import random               \n",
    "\n",
    "#For images operations\n",
    "import cv2             \n",
    "import pydicom          \n",
    "import scipy\n",
    "from PIL import Image     \n",
    "from numpy import expand_dims  \n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras     \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout,BatchNormalization,Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version\t        Python version\tCompiler\tBuild tools\t     cuDNN\tCUDA\n",
    "\n",
    "# tensorflow-2.3.0\t3.5-3.8\t         GCC 7.3.1\t Bazel 3.1.0\t 7.6\t 10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:12:52_Pacific_Daylight_Time_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU devices found.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if there are any GPUs available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if len(physical_devices) == 0:\n",
    "    print(\"No GPU devices found.\")\n",
    "else:\n",
    "    print(\"Available GPU devices:\")\n",
    "    for device in physical_devices:\n",
    "        print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and visible to TensorFlow\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if len(physical_devices) == 0:\n",
    "    raise RuntimeError(\"No GPU devices found.\")\n",
    "\n",
    "# Print information about the GPU(s)\n",
    "for device in physical_devices:\n",
    "    print(\"Device name:\", device.name)\n",
    "\n",
    "# Optional: Limit GPU memory growth\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "# Your TensorFlow code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnn = PreNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_train = 'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/train'\n",
    "dir_test  = 'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/test'\n",
    "dir_valid = 'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/validation'\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "width = 512\n",
    "length = 512\n",
    "channel = 3\n",
    "image_size = (width, length)\n",
    "random.seed(123) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como est√° dando o CLOCK_WATCHDOG_TIMEOUT reduzirei a quantidade de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total training  {len(os.listdir(dir_train))}')\n",
    "print(f'Total validation {len(os.listdir(dir_valid))}')\n",
    "print(f'Total test {len(os.listdir(dir_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen= ImageDataGenerator(rescale=1.0/255, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,)\n",
    "val_datagen  = ImageDataGenerator(rescale=1.0/255, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(dir_train,\n",
    "                                        target_size=image_size,\n",
    "                                        color_mode='grayscale',  # Ensure RGB color mode\n",
    "                                        class_mode='categorical',  # Adjust class_mode as needed\n",
    "                                        batch_size=batch_size,\n",
    "                                        subset='training',  # Specify 'training' for the training set\n",
    "                                        \n",
    "                                    )\n",
    "\n",
    "val_generator=val_datagen.flow_from_directory(dir_valid,\n",
    "                                        target_size=image_size,\n",
    "                                        color_mode='grayscale',\n",
    "                                        class_mode='categorical',\n",
    "                                        batch_size=batch_size\n",
    "                                    )\n",
    "\n",
    "test_generator=test_datagen.flow_from_directory(dir_test,\n",
    "                                        target_size=image_size,\n",
    "                                        color_mode='grayscale',\n",
    "                                        class_mode='categorical',\n",
    "                                        batch_size=batch_size\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Specify GPU device\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU is available and accessible.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = train_generator.num_classes\n",
    "print(\"Number of classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For files e data manipulations\n",
    "from neuralNetwork import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# image_shape = (width, length, channel)  # Adjust image dimensions as needed\n",
    "\n",
    "# B7 = EfficientNetModelB7(n_classes, image_shape)\n",
    "# # Train the model\n",
    "# modelB7 = B7.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "#     historyB7 = B7.train(train_generator, val_generator, modelB7, epochs=20, batch_size=batch_size, early_stop_patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "65165svsvdsfzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_shape = (width, length, channel) \n",
    "image_shape = (128, 128, channel) \n",
    "\n",
    "base_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "output = base_model.output\n",
    "output = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(1024, activation='relu')(output)\n",
    "output = BatchNormalization()(output)\n",
    "\n",
    "    \n",
    "predictions = Dense(n_classes, activation='softmax')(output)\n",
    "modelB7 = Model(inputs=base_model.input, outputs=predictions)\n",
    "modelB7.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    # historyB7 = B7.train(train_generator, val_generator, modelB7, epochs=20, batch_size=batch_size, early_stop_patience=30)\n",
    "    history = modelB7.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=20,\n",
    "        batch_size=2#,\n",
    "        #callbacks=[early_stop_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = model.create_metrics_dataframe(history_b7)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_history(history_b7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet101Model(num_classes, image_shape)\n",
    "\n",
    "# Train the model\n",
    "history_101 = model.train(train_generator, val_generator, epochs=20, batch_size=batch_size, early_stop_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "df_results = model.create_metrics_dataframe(history_101)\n",
    "model.plot_history(history_101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lessinha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
