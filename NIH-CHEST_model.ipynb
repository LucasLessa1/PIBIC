{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For files e data manipulations\n",
    "from imports_ import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnn = PreNeuralNetwork(train='C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/train', test='C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/test' ,\n",
    "                    valid='C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_train = 'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/train'\n",
    "dir_test  = 'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/test'\n",
    "dir_valid = 'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/archive/validation'\n",
    "\n",
    "batch_size = 4  \n",
    "image_size = (224, 224)\n",
    "\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77877 images belonging to 9 classes.\n",
      "Found 4328 images belonging to 9 classes.\n",
      "Found 4326 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen= ImageDataGenerator(rescale=1.0/255)\n",
    "val_datagen  = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(dir_train,\n",
    "                                        target_size=image_size,\n",
    "                                        color_mode='rgb',  # Ensure RGB color mode\n",
    "                                        class_mode='categorical',  # Adjust class_mode as needed\n",
    "                                        batch_size=batch_size,\n",
    "                                        subset='training',  # Specify 'training' for the training set\n",
    "                                    )\n",
    "\n",
    "val_generator=val_datagen.flow_from_directory( dir_valid,\n",
    "                                        target_size=image_size,\n",
    "                                        color_mode='rgb',\n",
    "                                        class_mode='sparse',batch_size=batch_size)\n",
    "\n",
    "test_generator=test_datagen.flow_from_directory(dir_test,\n",
    "                                        target_size=image_size,\n",
    "                                        color_mode='rgb',\n",
    "                                        class_mode='sparse',batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.preprocessing.image.DirectoryIterator at 0x16a81395e50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 9\n"
     ]
    }
   ],
   "source": [
    "n_classes = train_generator.num_classes\n",
    "print(\"Number of classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet101Model:\n",
    "    def __init__(self, num_classes, image_shape):\n",
    "        self.num_classes = num_classes\n",
    "        self.image_shape = image_shape\n",
    "        self.model = self.build_model()\n",
    "        self.metrics_df = pd.DataFrame(columns=['epoch', 'train_loss', 'val_loss', 'train_accuracy', 'val_accuracy'])\n",
    "    \n",
    "    def build_model(self):\n",
    "        base_model = ResNet101(weights='imagenet', include_top=False, input_shape=self.image_shape)\n",
    "        x = GlobalAveragePooling2D()(base_model.output)\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        predictions = Dense(self.num_classes, activation='softmax')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def train(self, train_data, val_data, epochs, batch_size, early_stop_patience=5):\n",
    "        early_stop_callback = EarlyStopping(monitor='val_loss', patience=early_stop_patience, restore_best_weights=True)\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            train_data,\n",
    "            validation_data=val_data,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[early_stop_callback]\n",
    "        )\n",
    "        \n",
    "        self.update_metrics(history)\n",
    "    \n",
    "    def update_metrics(self, history):\n",
    "        for epoch, train_loss, val_loss, train_accuracy, val_accuracy in zip(\n",
    "                range(len(history.history['loss'])),\n",
    "                history.history['loss'],\n",
    "                history.history['val_loss'],\n",
    "                history.history['accuracy'],\n",
    "                history.history['val_accuracy']\n",
    "        ):\n",
    "            self.metrics_df = self.metrics_df.append({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'train_accuracy': train_accuracy,\n",
    "                'val_accuracy': val_accuracy\n",
    "            }, ignore_index=True)\n",
    "        return self.metrics_df\n",
    "    def evaluate(self, test_data):\n",
    "        return self.model.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_9176\\971669406.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is not available.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU is available and accessible.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a GPU with index 0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Specify GPU device\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid imaginary literal (3556377177.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    5641jyhgvuy\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid imaginary literal\n"
     ]
    }
   ],
   "source": [
    "5641jyhgvuy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  38/2434 [..............................] - ETA: 1:34:28 - loss: 1.2936 - accuracy: 0.6678"
     ]
    }
   ],
   "source": [
    "# Create an instance of ResNet101Model\n",
    "num_classes = n_classes  # Adjust the number of classes as needed\n",
    "image_shape = (224,224,3)  # Adjust image dimensions as needed\n",
    "model = ResNet101Model(num_classes, image_shape)\n",
    "\n",
    "# Train the model\n",
    "model.train(train_generator, val_generator, epochs=10, batch_size=batch_size, early_stop_patience=5)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "\n",
    "# Access and analyze training and validation metrics\n",
    "metrics_df = model.metrics_df\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vgg16 = keras.applications.vgg16\n",
    "# vgg = vgg16.VGG16(input_shape = (img_width, img_height, 3), \n",
    "#                        include_top = False, \n",
    "#                        weights = 'imagenet')\n",
    "\n",
    "# # vgg.summary()\n",
    "# # Layer of transfer learning not trainable\n",
    "# # vgg.trainable = False\n",
    "# for layer in vgg.layers:\n",
    "#   layer.trainable = False\n",
    "  \n",
    "# output = vgg.output\n",
    "# # three hidden layers\n",
    "# # output = keras.layers.GlobalAveragePooling2D()(output)\n",
    "# output = keras.layers.Flatten()(output)\n",
    "# output = keras.layers.Dense(512, activation='relu')(output)\n",
    "# output = keras.layers.Dropout(0.75)(output) \n",
    "# output = BatchNormalization()(output)\n",
    "# output = keras.layers.Dropout(0.5)(output) \n",
    "# # output = keras.layers.Dense(22, activation='relu')(output)\n",
    "# # final softmax layer\n",
    "\n",
    "# predictions = keras.layers.Dense(len(bodyparts), activation='softmax')(output)\n",
    "\n",
    "# # creating the full model:\n",
    "# full_model = keras.models.Model(inputs=vgg.input, outputs=predictions)\n",
    "# full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir model_NIG-CHEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'model_NIG-CHEST/model_vgg_{qntd_for_model}_1.h5', \n",
    "                                                verbose = 1, \n",
    "                                                save_best = True, \n",
    "                                                save_weights_only = True)\n",
    "\n",
    "# Early stop\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience = 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = full_model.fit(train_ds, \n",
    "                        epochs=50,\n",
    "                        validation_data=val_ds,\n",
    "                        workers=5,\n",
    "                        callbacks = [checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lessinha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
