{"cells":[{"cell_type":"markdown","metadata":{},"source":["# COVID-19 CT Image Classification Using PyTorch\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Data Preparation\n","\n","* Import dependecies\n","* Extract file paths and split into training, validation, and test partitions\n","* Create Dataset Class to process and load images for PyTorch models "]},{"cell_type":"markdown","metadata":{},"source":["### 1.1 Import all dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:05:11.118554Z","iopub.status.busy":"2022-01-02T01:05:11.117796Z","iopub.status.idle":"2022-01-02T01:05:13.680413Z","shell.execute_reply":"2022-01-02T01:05:13.679697Z","shell.execute_reply.started":"2022-01-02T01:05:11.118516Z"},"trusted":true},"outputs":[],"source":["import os  \n","import glob\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","import PIL \n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt \n","\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from efficientnet_pytorch import EfficientNet\n","from torchinfo import summary \n","\n","import torch.optim as optim\n","from IPython.display import Image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import transforms\n","import torch.nn.functional as F\n","\n","import pydicom\n","from PIL import Image\n","\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:05:26.643276Z","iopub.status.busy":"2022-01-02T01:05:26.643017Z","iopub.status.idle":"2022-01-02T01:05:26.689544Z","shell.execute_reply":"2022-01-02T01:05:26.688904Z","shell.execute_reply.started":"2022-01-02T01:05:26.643247Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device "]},{"cell_type":"markdown","metadata":{},"source":["Set Random Seed for reproducability"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:07:17.417698Z","iopub.status.busy":"2022-01-02T01:07:17.417439Z","iopub.status.idle":"2022-01-02T01:07:17.425362Z","shell.execute_reply":"2022-01-02T01:07:17.424534Z","shell.execute_reply.started":"2022-01-02T01:07:17.417671Z"},"trusted":true},"outputs":[],"source":["random_seed = 124\n","np.random.seed(random_seed)\n","\n","torch.manual_seed(random_seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_pth = 'C:/Users/Lucas Lessa/Documents/CANCER_IMAGING_ARCHIVE/train_images'\n","test_pth = 'C:/Users/Lucas Lessa/Documents/CANCER_IMAGING_ARCHIVE/test_images'\n","valid_pth = 'C:/Users/Lucas Lessa/Documents/CANCER_IMAGING_ARCHIVE/valid_images'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import re\n","\n","def create_dataset(directory):\n","    dataset = {'path': [], 'label': []}\n","    for root, dirs, files in os.walk(directory):\n","        for file in files:\n","            if file.endswith(\".png\"):  # assuming the images are in .png format\n","                path = f'{root}/{file}'\n","                label = re.search('cancer_(.*?)_', file).group(1)\n","                dataset['path'].append(path)\n","                dataset['label'].append(int(label))\n","    return pd.DataFrame(dataset)\n","\n","train_df = create_dataset(train_pth)\n","test_df = create_dataset(test_pth)\n","valid_df = create_dataset(valid_pth)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["valid_df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sum(list(train_df['label']))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_path, train_label = list(train_df['path']), list(train_df['label'])\n","test_path, test_label = list(test_df['path']), list(test_df['label'])\n","valid_path, valid_label = list(valid_df['path']), list(valid_df['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:04:26.504349Z","iopub.status.busy":"2022-01-02T02:04:26.504074Z","iopub.status.idle":"2022-01-02T02:04:26.509169Z","shell.execute_reply":"2022-01-02T02:04:26.508291Z","shell.execute_reply.started":"2022-01-02T02:04:26.504319Z"},"trusted":true},"outputs":[],"source":["print(f'Number of samples in each set (train, val, test): {len(train_path), len(valid_path), len(test_path)}')\n","\n","print(f'Number of positive samples in each set: {sum(train_label), sum(valid_label), sum(test_label)}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train_path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["total_samples = len(train_path) + len(valid_path) + len(test_path)\n","pos_samples = sum(train_label) + sum(valid_label) + sum(test_label)\n","\n","weight_for_cancer = total_samples/(pos_samples * 2)\n","weight_for_not_cancer = total_samples/(total_samples-pos_samples  * 2)\n","\n","print(f'The weight for cancer is {weight_for_cancer:.5f} \\n\\nThe weight for not cancer is {weight_for_not_cancer:.5f} ')"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset Class\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:06:32.906034Z","iopub.status.busy":"2022-01-02T02:06:32.905735Z","iopub.status.idle":"2022-01-02T02:06:32.915082Z","shell.execute_reply":"2022-01-02T02:06:32.914103Z","shell.execute_reply.started":"2022-01-02T02:06:32.906002Z"},"trusted":true},"outputs":[],"source":["class CT_Dataset(Dataset):\n","    def __init__(self, img_path, img_labels, img_transforms=None, grayscale=True):\n","        self.img_path = img_path\n","        self.img_labels = torch.Tensor(img_labels)\n","        if (img_transforms is None) & (grayscale == True):\n","            self.transforms = transforms.Compose([transforms.Grayscale(),\n","                                                  transforms.Resize((250, 250)),\n","                                                  transforms.ToTensor()])\n","        elif grayscale == False:\n","            self.transforms = transforms.Compose([transforms.Resize((250, 250)),\n","                                                  transforms.ToTensor()])\n","        else:\n","            self.transforms = img_transforms\n","    \n","    def __getitem__(self, index):\n","        # load image\n","        cur_path = self.img_path[index]\n","        cur_img = PIL.Image.open(cur_path).convert('RGB')\n","        cur_img = self.transforms(cur_img)\n","\n","        return cur_img, self.img_labels[index]\n","    \n","    def __len__(self):\n","        return len(self.img_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Model Development"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet50"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","class ResNet50(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(ResNet50, self).__init__()\n","        self.resnet50 = models.resnet50(weights=True)\n","        self.resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        in_features = self.resnet50.fc.in_features\n","        self.resnet50.fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.resnet50(x)\n","    \n","    def get_name(self):\n","        return 'ResNet50'\n","\n","# class CustomResNet50(nn.Module):\n","#     def __init__(self, num_classes=1):\n","#         super(CustomResNet50, self).__init()\n","#         self.resnet50 = models.resnet50(pretrained=True)\n","        \n","#         # Modify the first layer to accept 1 channel input\n","        \n","#         in_features = self.resnet50.fc.in_features\n","#         self.resnet50.fc = nn.Sequential(\n","#             nn.Linear(in_features, 512),\n","#             nn.ReLU(),\n","#             nn.Dropout(0.1),\n","#             nn.Linear(512, num_classes)\n","#         )\n","\n","#     def forward(self, x):\n","#         return self.resnet50(x)\n"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet101"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ResNet101(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(ResNet101, self).__init__()\n","        self.resnet101 = models.resnet101(pretrained=True)\n","        in_features = self.resnet101.fc.in_features\n","        self.resnet101.fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.resnet101(x)\n","    \n","    def get_name(self):\n","        return 'ResNet101'"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class EfficientNetB0(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(EfficientNetB0, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b0')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n","    \n","    def get_name(self):\n","        return 'EfficientNetB0'"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB4"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class EfficientNetB4(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(EfficientNetB4, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b4')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n","    \n","    def get_name(self):\n","        return 'EfficientNetB4'"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB7"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class EfficientNetB7(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(EfficientNetB7, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b7')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n","    \n","    def get_name(self):\n","        return 'EfficientNetB7'"]},{"cell_type":"markdown","metadata":{},"source":["### VGG16"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class VGG16(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(VGG16, self).__init__()\n","        self.vgg16 = models.vgg16(pretrained=True)\n","        in_features = self.vgg16.classifier[6].in_features\n","        self.vgg16.classifier[6] = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.vgg16(x)\n","    \n","    def get_name(self):\n","        return 'VGG16'"]},{"cell_type":"markdown","metadata":{},"source":["### Function train_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:38:15.316255Z","iopub.status.busy":"2022-01-02T02:38:15.315802Z","iopub.status.idle":"2022-01-02T02:38:15.333659Z","shell.execute_reply":"2022-01-02T02:38:15.332954Z","shell.execute_reply.started":"2022-01-02T02:38:15.316218Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","# Define the training function\n","def train_model(model, train_dataset, val_dataset, test_dataset, device,path_save_model,\n","                lr=0.0001, epochs=30, batch_size=32, l2=0.00001, gamma=0.5,\n","                patience=7):\n","    model = model.to(device)\n","\n","    # Construct dataloader\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    # History\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n","\n","    #Weight for the unbalanced class\n","    weight = torch.tensor([weight_for_cancer]).to(device)\n","    # Set up loss function and optimizer\n","    criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=patience, gamma=gamma)\n","\n","    # Initialize variables to track the best validation loss and corresponding model state\n","    best_val_loss = float('inf')\n","    best_model_state = None\n","\n","    # Training Loop\n","    print(\"Training Start:\")\n","    for epoch in range(epochs):\n","        model.train()\n","\n","        train_loss = 0\n","        train_acc = 0\n","        val_loss = 0\n","        val_acc = 0\n","\n","        for (images, labels) in train_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images).view(-1)\n","            labels = labels.view(-1)\n","            pred = torch.sigmoid(outputs)\n","            pred = torch.round(pred)\n","            # print(type(outputs))\n","            # print(type(labels))\n","            # print(outputs.shape, labels.shape)\n","            cur_train_loss = criterion(outputs, labels)\n","            cur_train_acc = (pred == labels).sum().item() / batch_size\n","\n","            cur_train_loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            train_loss += cur_train_loss\n","            train_acc += cur_train_acc\n","       \n","        model.eval()\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","                outputs = model(images).view(-1)\n","\n","                # print(outputs.shape, labels.shape)\n","                cur_valid_loss = criterion(outputs, labels)\n","                val_loss += cur_valid_loss\n","\n","                pred = torch.sigmoid(outputs)\n","                pred = torch.round(pred)\n","                val_acc += (pred == labels).sum().item() / batch_size\n","\n","        scheduler.step()\n","\n","        train_loss = train_loss / len(train_loader)\n","        train_acc = train_acc / len(train_loader)\n","        val_loss = val_loss / len(val_loader)\n","        val_acc = val_acc / len(val_loader)\n","\n","        print(f\"Epoch:{epoch + 1} / {epochs}, lr: {optimizer.param_groups[0]['lr']:.5f} train loss:{train_loss:.5f}, train acc: {train_acc:.5f}, valid loss:{val_loss:.5f}, valid acc:{val_acc:.5f}\")\n","   \n","        history['train_loss'].append(train_loss)\n","        history['train_acc'].append(train_acc)\n","        history['val_loss'].append(val_loss)\n","        history['val_acc'].append(val_acc)\n","   \n","        # Update the best model if validation loss is the lowest so far\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            best_model_state = model.state_dict()\n","\n","    # Load the best model state\n","    if best_model_state is not None:\n","        model.load_state_dict(best_model_state)\n","\n","    test_acc = 0\n","    print(f'The best val loss is {best_val_loss}.\\n\\n')\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device).long()   # Convert labels to Long data type\n","\n","            outputs = model(images).float()  # Make sure the output is of type float\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predictions)\n","            pred = outputs.argmax(dim=1)  ####################################################\n","            # pred = torch.nn.functional.one_hot(pred, num_classes=num_classes).cpu().numpy()\n","            test_acc += (pred == labels).sum().item()\n","\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","   \n","        # Calculate evaluation metrics\n","    accuracy = (test_acc / len(test_loader))\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","    specificity = tn / (tn + fp)\n","    sensitivity = tp / (fn + tp)\n","\n","    metrics = {\n","        'precision': precision,\n","        'recall': recall,\n","        'f1_score': f1,\n","        'accuracy': accuracy,\n","        'specificity': specificity,\n","        'sensitivity': sensitivity,\n","        'false negativo': fn\n","    }\n","   \n","    pd.DataFrame(metrics.items(), columns=['Metric', 'Value']).to_csv(f'{path_save_model}.csv')\n","    print(f'Test Accuracy:  {(test_acc / len(test_loader))}')\n","\n","    return history, model"]},{"cell_type":"markdown","metadata":{},"source":["Process the datasets and train the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Current GPU memory usage:\", torch.cuda.memory_allocated() / (1024 ** 2), \"MB\")\n","print(\"Max GPU memory usage:\", torch.cuda.max_memory_allocated() / (1024 ** 2), \"MB\")\n","\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(train_path), len(train_label)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataset = CT_Dataset(img_path=train_path, img_labels=np.array(train_label))\n","val_dataset = CT_Dataset(img_path=valid_path, img_labels=np.array(valid_label))\n","test_dataset = CT_Dataset(img_path=test_path, img_labels=np.array(test_label))"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:40:25.322238Z","iopub.status.busy":"2022-01-02T02:40:25.321990Z","iopub.status.idle":"2022-01-02T02:42:57.004380Z","shell.execute_reply":"2022-01-02T02:42:57.003631Z","shell.execute_reply.started":"2022-01-02T02:40:25.322210Z"},"trusted":true},"outputs":[],"source":["batch_size = 32\n","epoch = 50\n","\n","\n","# Train the ResNet101 model\n","model_kernel = ResNet50(num_classes=1)\n","# model_kernel = ResNet101(num_classes=1)\n","# model_kernel = EfficientNetB(num_classes=1)\n","# model_kernel = EfficientNetB4(num_classes=1)\n","# model_kernel = EfficientNetB7(num_classes=1)\n","# model_kernel = VGG16(num_classes=1)\n","\n","\n","\n","\n","path_save_model = f'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/model_/{model_kernel.get_name()}_{epoch}'\n","hist_kernel, model_kernel = train_model(model_kernel, train_dataset, val_dataset, test_dataset, device, path_save_model, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["546165sdvsdvsdv4"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["label_model = model_kernel.get_name()\n","# hist_kernel = hist_ResNet50\n","# model_kernel = model_ResNet50\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path_save_model = f'C:/Users/Lucas/Documents/PIBIC/DATASET/CANCER_IMAGING_ARCHIVE/model_/{label_model}_epoch_{epoch}'\n","\n","torch.save(model_kernel.state_dict(), f'{path_save_model}.pth')"]},{"cell_type":"markdown","metadata":{},"source":["## Metricis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_metrics(hist, label_model) :\n","    # plot training curves\n","    epochs = range(1, len(hist['train_loss']) + 1)\n","\n","    train_loss = [t.cpu().detach().numpy() for t in hist['train_loss']]\n","    val_loss = [t.cpu().detach().numpy() for t in hist['val_loss']]\n","\n","\n","    fig, ax = plt.subplots(1,2, figsize=(20,6))\n","    ax[0].plot(epochs, train_loss, 'r-', label='Train')\n","    ax[0].plot(epochs, val_loss, 'b-', label='Evaluation')\n","    ax[0].set_title('Loss')\n","    ax[0].set_xlabel('Epochs')\n","    ax[0].set_ylabel('Loss')\n","    ax[0].legend()\n","    plt.savefig(f'{path_save_model}_Loss.png')  # This saves the plot as a PNG image\n","\n","    ax[1].plot(epochs, hist['train_acc'], 'r-', label='Train')\n","    ax[1].plot(epochs, hist['val_acc'], 'b-', label='Evaluation')\n","    ax[1].set_title('Accuracy')\n","    ax[1].set_xlabel('Epochs')\n","    ax[1].set_ylabel('Acc')\n","    ax[1].legend()\n","    plt.savefig(f'{path_save_model}_Accuracy.png')  # This saves the plot as a PNG image\n","    \n","\n","    plt.show()\n","    \n","    \n","plot_metrics(hist_kernel, label_model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calculate_metrics(model, test_dataset, device, plot_images=False):\n","    # Initialize variables to store predictions and ground truth\n","    y_true = []\n","    y_pred = []\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predictions)\n","\n","    # Convert lists to numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","    # Calculate evaluation metrics\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    accuracy = accuracy_score(y_true, y_pred)\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = tp / (fn + tp)\n","\n","    metrics = {\n","        'precision': precision,\n","        'recall': recall,\n","        'f1_score': f1,\n","        'accuracy': accuracy,\n","        'specificity': specificity,\n","        'sensitivity': sensitivity,\n","        'false negativo': fn\n","    }\n","\n","    return metrics\n","\n","\n","\n","\n","model_path = f'{path_save_model}.pth'\n","if label_model == \"ResNet50\":\n","    model_kernel = ResNet50(num_classes=1)\n","\n","elif label_model == \"ResNet101\":\n","    model_kernel = ResNet101(num_classes=1)\n","\n","\n","elif label_model == \"EfficientNetB0\":\n","    model_kernel = EfficientNetB0(num_classes=1)\n","    \n","elif label_model == \"EfficientNetB4\":\n","    model_kernel = EfficientNetB4(num_classes=1)\n","\n","elif label_model == \"EfficientNetB7\":\n","    model_kernel = EfficientNetB7(num_classes=1)\n","\n","elif label_model == \"VGG16\":\n","    model_kernel = VGG16(num_classes=1)\n","\n","\n","model_kernel.load_state_dict(torch.load(model_path))\n","model_kernel.to(device)  # Move the model to the specified device\n","model_kernel.eval()  # Set the model to evaluation mode\n","\n","# Call the function with plot_images=True to plot images\n","metrics = calculate_metrics(model_kernel, test_dataset, device, plot_images=True)\n","metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.DataFrame(metrics.items(), columns=['Metric', 'Value']).to_csv(f'{path_save_model}.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_images(model, test_dataset, device, plot_images=False, num_images_to_plot=10):\n","    # Initialize variables to store predictions and ground truth\n","    y_pred = []\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","    images_plotted = 0  # Counter for the number of images plotted\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_pred.extend(predictions)\n","\n","            # Plot images with true and predicted labels\n","            if plot_images and images_plotted < num_images_to_plot:\n","                plot_image(images, labels, predictions)\n","                images_plotted += 1\n","\n","            # Break the loop if the desired number of images is plotted\n","            if images_plotted >= num_images_to_plot:\n","                break\n","\n","\n","def plot_image(images, true_label, predicted_label):\n","    if len(images.shape) == 4 and images.shape[1] == 3:\n","        # Convert CUDA tensor to numpy array and rearrange dimensions for RGB image\n","        images = images.cpu().detach().numpy().squeeze().transpose((1, 2, 0))\n","    else:\n","        # Convert CUDA tensor to numpy array and squeeze if necessary\n","        images = images.cpu().detach().numpy().squeeze()\n","\n","    if len(images.shape) == 2:\n","        plt.imshow(images, cmap='gray')\n","    else:\n","        plt.imshow(images)\n","    \n","    # Format the labels\n","    true_label = true_label.item() if isinstance(true_label, torch.Tensor) else true_label\n","    predicted_label = predicted_label.item() if isinstance(predicted_label, torch.Tensor) else predicted_label\n","    \n","    plt.title(f'True label: {true_label}; Predicted: {predicted_label}')\n","    plt.show()\n","    \n","    \n","process_images(model_kernel, test_dataset, device, plot_images=True)"]},{"cell_type":"markdown","metadata":{},"source":["**Sugestão de Próximos Passos**\n","\n","1. Colocar para salvar o modelo com a menor validation loss.\n","2. Colocar código para carregar o modelo salvo e fazer predições em imagens do dataset.\n","3. Criar métricas de acurácia (Accuracy, Precision, Recall, F-score, etc.) para avaliar o dataset de teste com o modelo salvo.\n","\n","Quando tudo estiver pronto:\n","4. Criar novos modelos CNN (começar pela ResNet101).\n","5. Implementar outros modelos.\n","\n","Quando estiver pronto:\n","6. Implementar no seu dataset.\n"]},{"cell_type":"markdown","metadata":{},"source":["Para binário tem que mudar a loss (CrossEntropy), a sigmoid da layer final para softmax"]},{"cell_type":"markdown","metadata":{},"source":["# Materiais e Métodos\n","\n","## 1. Datasets\n","\n","Explicação sobre os conjuntos de dados utilizados.\n","\n","## 2. Modelos\n","\n","Explicação sobre como funciona um modelo CNN (Convolutional Neural Network) e os parâmetros utilizados.\n","\n","### 2.1. EfficientNet\n","\n","### 2.2. ResNet101\n","\n","...\n","\n","## 3. Métricas\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
