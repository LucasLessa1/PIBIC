{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # https://github.com/ari-dasci/OD-covidgr\n","# @misc{tabik2020covidgr,\n","#     title={COVIDGR dataset and COVID-SDNet methodology for predicting COVID-19 based on Chest X-Ray images},\n","#     author={S. Tabik and A. Gómez-Ríos and J. L. Martín-Rodríguez and I. Sevillano-García and M. Rey-Area and D. Charte and E. Guirado and J. L. Suárez and J. Luengo and M. A. Valero-González and P. García-Villanova and E. Olmedo-Sánchez and F. Herrera},\n","#     year={2020},\n","#     eprint={2006.01409},\n","#     archivePrefix={arXiv},\n","#     primaryClass={eess.IV}\n","# }"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:05:11.118554Z","iopub.status.busy":"2022-01-02T01:05:11.117796Z","iopub.status.idle":"2022-01-02T01:05:13.680413Z","shell.execute_reply":"2022-01-02T01:05:13.679697Z","shell.execute_reply.started":"2022-01-02T01:05:11.118516Z"},"trusted":true},"outputs":[],"source":["import os  \n","import glob\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","import PIL \n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt \n","\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from efficientnet_pytorch import EfficientNet\n","from torchinfo import summary \n","\n","import torch.optim as optim\n","from IPython.display import Image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import transforms\n","import torch.nn.functional as F\n","\n","\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:05:26.643276Z","iopub.status.busy":"2022-01-02T01:05:26.643017Z","iopub.status.idle":"2022-01-02T01:05:26.689544Z","shell.execute_reply":"2022-01-02T01:05:26.688904Z","shell.execute_reply.started":"2022-01-02T01:05:26.643247Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device "]},{"cell_type":"markdown","metadata":{},"source":["Set Random Seed for reproducability"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:07:17.417698Z","iopub.status.busy":"2022-01-02T01:07:17.417439Z","iopub.status.idle":"2022-01-02T01:07:17.425362Z","shell.execute_reply":"2022-01-02T01:07:17.424534Z","shell.execute_reply.started":"2022-01-02T01:07:17.417671Z"},"trusted":true},"outputs":[],"source":["random_seed = 124\n","np.random.seed(random_seed)\n","\n","torch.manual_seed(random_seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{},"source":["### 1.2 Generating Labels and Creating Sets for Modeling\n","\n","Extract file links for both postive and negative images and split the dataset into train, validation, and test sets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:07:45.349785Z","iopub.status.busy":"2022-01-02T01:07:45.349043Z","iopub.status.idle":"2022-01-02T01:07:45.366110Z","shell.execute_reply":"2022-01-02T01:07:45.365338Z","shell.execute_reply.started":"2022-01-02T01:07:45.349735Z"},"trusted":true},"outputs":[],"source":["path = 'C:/Users/Lucas/Documents/PIBIC/DATASET/COVIDGR_datasets'\n","\n","pos_files = glob.glob(f'{path}/P/*.*')\n","neg_files = glob.glob(f'{path}/N/*.*')\n","\n","images = pos_files + neg_files\n","labels = np.array([1]*len(pos_files)+[0]*len(neg_files))\n","\n","images_tv, images_test, y_tv, y_test  = train_test_split(images, labels, shuffle=True, test_size=0.2, random_state=random_seed)\n","images_train, images_val, y_train, y_val  = train_test_split(images_tv, y_tv, shuffle=True, test_size=0.25, random_state=random_seed)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(images_tv), len(images_test)"]},{"cell_type":"markdown","metadata":{},"source":["From the plot below, observe that we have a balanced yet very small dataset at our disposal. Not ideal, but never the end of the road. Let's do our best to make the most out of what we have before we collect more data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:04:17.870510Z","iopub.status.busy":"2022-01-02T02:04:17.869831Z","iopub.status.idle":"2022-01-02T02:04:18.020923Z","shell.execute_reply":"2022-01-02T02:04:18.020206Z","shell.execute_reply.started":"2022-01-02T02:04:17.870462Z"},"trusted":true},"outputs":[],"source":["num_pos, num_neg = len(pos_files), len(neg_files)\n","\n","plt.title('Distribution of labels')\n","plt.bar(['Positive', 'Negative'], [num_pos, num_neg])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Let's take a look at some of the images!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:04:20.629635Z","iopub.status.busy":"2022-01-02T02:04:20.629362Z","iopub.status.idle":"2022-01-02T02:04:20.646823Z","shell.execute_reply":"2022-01-02T02:04:20.646094Z","shell.execute_reply.started":"2022-01-02T02:04:20.629606Z"},"trusted":true},"outputs":[],"source":["Image(images_train[1])\n","Image(images_train[15])\n","Image(images_train[66])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:04:22.705642Z","iopub.status.busy":"2022-01-02T02:04:22.705030Z","iopub.status.idle":"2022-01-02T02:04:23.493539Z","shell.execute_reply":"2022-01-02T02:04:23.492877Z","shell.execute_reply.started":"2022-01-02T02:04:22.705604Z"},"trusted":true},"outputs":[],"source":["im = [cv2.imread(images_train[i]) for i in range(6)]\n","\n","fig,ax = plt.subplots(ncols=6, figsize=(18,6))\n","for i in range(len(im)):\n","    ax[i].imshow(im[i],cmap='gray')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:04:26.504349Z","iopub.status.busy":"2022-01-02T02:04:26.504074Z","iopub.status.idle":"2022-01-02T02:04:26.509169Z","shell.execute_reply":"2022-01-02T02:04:26.508291Z","shell.execute_reply.started":"2022-01-02T02:04:26.504319Z"},"trusted":true},"outputs":[],"source":["print(f'Number of samples in each set (train, val, test): {len(y_train), len(y_val), len(y_test)}')\n","\n","print(f'Number of positive samples in each set: {y_train.sum(), y_val.sum(), y_test.sum()}')"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset Class\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:06:32.906034Z","iopub.status.busy":"2022-01-02T02:06:32.905735Z","iopub.status.idle":"2022-01-02T02:06:32.915082Z","shell.execute_reply":"2022-01-02T02:06:32.914103Z","shell.execute_reply.started":"2022-01-02T02:06:32.906002Z"},"trusted":true},"outputs":[],"source":["class CT_Dataset(Dataset):\n","    def __init__(self, img_path, img_labels, img_transforms=None, grayscale=False):\n","        self.img_path = img_path\n","        self.img_labels = torch.Tensor(img_labels)\n","        if (img_transforms is None) & (grayscale == True):\n","            self.transforms = transforms.Compose([transforms.Grayscale(),\n","                                                  transforms.Resize((250, 250)),\n","                                                  transforms.ToTensor()])\n","        elif grayscale == False:\n","            self.transforms = transforms.Compose([transforms.Resize((250, 250)),\n","                                                  transforms.ToTensor()])\n","        else:\n","            self.transforms = img_transforms\n","    \n","    def __getitem__(self, index):\n","        # load image\n","        cur_path = self.img_path[index]\n","        cur_img = PIL.Image.open(cur_path).convert('RGB')\n","        cur_img = self.transforms(cur_img)\n","\n","        return cur_img, self.img_labels[index]\n","    \n","    def __len__(self):\n","        return len(self.img_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Model Development"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet101"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ResNet101(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(ResNet101, self).__init__()\n","        self.resnet101 = models.resnet101(pretrained=True)\n","        in_features = self.resnet101.fc.in_features\n","        self.resnet101.fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.resnet101(x)"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet50"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ResNet50(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(ResNet50, self).__init__()\n","        self.resnet50 = models.resnet50(pretrained=True)\n","        in_features = self.resnet50.fc.in_features\n","        self.resnet50.fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.resnet50(x)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class EfficientNetB0(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(EfficientNetB0, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b0')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB4"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class EfficientNetB4(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(EfficientNetB4, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b4')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB7"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class EfficientNetB7(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(EfficientNetB7, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b7')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n"]},{"cell_type":"markdown","metadata":{},"source":["### VGG16"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class VGG16(nn.Module):\n","    def __init__(self, num_classes=1):\n","        super(VGG16, self).__init__()\n","        self.vgg16 = models.vgg16(pretrained=True)\n","        in_features = self.vgg16.classifier[6].in_features\n","        self.vgg16.classifier[6] = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.vgg16(x)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:38:15.316255Z","iopub.status.busy":"2022-01-02T02:38:15.315802Z","iopub.status.idle":"2022-01-02T02:38:15.333659Z","shell.execute_reply":"2022-01-02T02:38:15.332954Z","shell.execute_reply.started":"2022-01-02T02:38:15.316218Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","# Define the training function\n","def train_model(model, train_dataset, val_dataset, test_dataset, device, \n","                lr=0.0001, epochs=30, batch_size=32, l2=0.00001, gamma=0.5,\n","                patience=7):\n","    model = model.to(device)\n","\n","    # Construct dataloader\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    # History\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n","\n","    # Set up loss function and optimizer\n","    criterion = nn.BCEWithLogitsLoss()  \n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=patience, gamma=gamma)\n","\n","    # Initialize variables to track the best validation loss and corresponding model state\n","    best_val_loss = float('inf')\n","    best_model_state = None\n","\n","    # Training Loop\n","    print(\"Training Start:\")\n","    for epoch in range(epochs):\n","        model.train()\n","\n","        train_loss = 0\n","        train_acc = 0\n","        val_loss = 0\n","        val_acc = 0\n","\n","        for i, (images, labels) in enumerate(train_loader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images).view(-1)\n","            pred = torch.sigmoid(outputs)\n","            pred = torch.round(pred)\n","    \n","            cur_train_loss = criterion(outputs, labels)\n","            cur_train_acc = (pred == labels).sum().item() / batch_size\n","\n","            cur_train_loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            train_loss += cur_train_loss \n","            train_acc += cur_train_acc\n","        \n","        model.eval()\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","\n","                outputs = model(images).view(-1)\n","\n","                cur_valid_loss = criterion(outputs, labels)\n","                val_loss += cur_valid_loss\n","\n","                pred = torch.sigmoid(outputs)\n","                pred = torch.round(pred)\n","                val_acc += (pred == labels).sum().item() / batch_size\n","\n","        scheduler.step()\n","\n","        train_loss = train_loss / len(train_loader)\n","        train_acc = train_acc / len(train_loader)\n","        val_loss = val_loss / len(val_loader)\n","        val_acc = val_acc / len(val_loader)\n","\n","        print(f\"Epoch:{epoch + 1} / {epochs}, lr: {optimizer.param_groups[0]['lr']:.5f} train loss:{train_loss:.5f}, train acc: {train_acc:.5f}, valid loss:{val_loss:.5f}, valid acc:{val_acc:.5f}\")\n","    \n","        history['train_loss'].append(train_loss)\n","        history['train_acc'].append(train_acc)\n","        history['val_loss'].append(val_loss)\n","        history['val_acc'].append(val_acc)\n","    \n","        # Update the best model if validation loss is the lowest so far\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            best_model_state = model.state_dict()\n","\n","    # Load the best model state\n","    if best_model_state is not None:\n","        model.load_state_dict(best_model_state)\n","\n","    test_acc = 0\n","    print(f'The best val loss is {best_val_loss}.\\n\\n')\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            outputs = model(images)\n","\n","            pred = torch.sigmoid(outputs)\n","            pred = torch.round(pred)\n","            test_acc += (pred == labels).sum().item()\n","\n","    print(f'Test Accuracy:  {(test_acc / len(test_loader))}')\n","\n","    return history, model"]},{"cell_type":"markdown","metadata":{},"source":["Process the datasets and train the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Current GPU memory usage:\", torch.cuda.memory_allocated() / (1024 ** 2), \"MB\")\n","print(\"Max GPU memory usage:\", torch.cuda.max_memory_allocated() / (1024 ** 2), \"MB\")\n","\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:40:25.322238Z","iopub.status.busy":"2022-01-02T02:40:25.321990Z","iopub.status.idle":"2022-01-02T02:42:57.004380Z","shell.execute_reply":"2022-01-02T02:42:57.003631Z","shell.execute_reply.started":"2022-01-02T02:40:25.322210Z"},"trusted":true},"outputs":[],"source":["# Load the data\n","train_dataset = CT_Dataset(img_path=images_train, img_labels=y_train)\n","val_dataset = CT_Dataset(img_path=images_val, img_labels=y_val)\n","test_dataset = CT_Dataset(img_path=images_test, img_labels=y_test)\n","\n","batch_size = 32\n","epoch = 10\n","\n","## Train the ResNet101 model\n","# model_resnet50 = ResNet50()\n","# hist_ResNet50, model_ResNet50 = train_model(model_resnet50, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)\n","\n","\n","# # Train the ResNet101 model\n","# model_resnet101 = ResNet101()\n","# hist_ResNet101, model_ResNet101 = train_model(model_resnet101, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)\n","\n","\n","# Train the EfficientNetB0 model\n","model_efficientnet_b0 = EfficientNetB0()\n","hist_EfficientNetB0, model_EfficientNetB0 = train_model(model_efficientnet_b0, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)\n","\n","\n","# Train the EfficientNetB4 model\n","# model_efficientnet_b4 = EfficientNetB4()\n","# hist_EfficientNetB4, model_EfficientNetB4 = train_model(model_efficientnet_b4, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)\n","\n","\n","# # Train the EfficientNetB7 model\n","# model_efficientnet_b7 = EfficientNetB7()\n","# hist_EfficientNetB7, model_EfficientNetB7 = train_model(model_efficientnet_b7, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)\n","\n","\n","# # Train the VGG16 model\n","# model_vgg16 = VGG16()\n","# hist_VGG16, model_VGG16 = train_model(model_vgg16, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if epoch == 50:\n","    id = 1\n","elif epoch == 100:\n","    id = 2\n","    \n","label_model = f\"EfficientNetB0_{id}\"\n","hist_kernel = hist_EfficientNetB0\n","model_kernel = model_EfficientNetB0\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save(model_kernel.state_dict(), f'C:/Users/Lucas/PIBIC/model_pytorch_/{label_model}.pth')"]},{"cell_type":"markdown","metadata":{},"source":["## Metricis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_metrics(hist, label_model) :\n","    # plot training curves\n","    epochs = range(1, len(hist['train_loss']) + 1)\n","\n","    train_loss = [t.cpu().detach().numpy() for t in hist['train_loss']]\n","    val_loss = [t.cpu().detach().numpy() for t in hist['val_loss']]\n","\n","\n","    fig, ax = plt.subplots(1,2, figsize=(20,6))\n","    ax[0].plot(epochs, train_loss, 'r-', label='Train')\n","    ax[0].plot(epochs, val_loss, 'b-', label='Evaluation')\n","    ax[0].set_title('Loss')\n","    ax[0].set_xlabel('Epochs')\n","    ax[0].set_ylabel('Loss')\n","    ax[0].legend()\n","    plt.savefig(f'C:/Users/Lucas/PIBIC/model_pytorch_/metrics/loss{label_model}.png')  # This saves the plot as a PNG image\n","\n","    ax[1].plot(epochs, hist['train_acc'], 'r-', label='Train')\n","    ax[1].plot(epochs, hist['val_acc'], 'b-', label='Evaluation')\n","    ax[1].set_title('Accuracy')\n","    ax[1].set_xlabel('Epochs')\n","    ax[1].set_ylabel('Acc')\n","    ax[1].legend()\n","    plt.savefig(f'C:/Users/Lucas/PIBIC/model_pytorch_/metrics/accuracy{label_model}.png')  # This saves the plot as a PNG image\n","    \n","\n","    plt.show()\n","    \n","    \n","plot_metrics(hist_kernel, label_model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calculate_metrics(model, test_dataset, device, plot_images=False):\n","    # Initialize variables to store predictions and ground truth\n","    y_true = []\n","    y_pred = []\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predictions)\n","\n","    # Convert lists to numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","    # Calculate evaluation metrics\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    accuracy = accuracy_score(y_true, y_pred)\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = tp / (fn + tp)\n","\n","    metrics = {\n","        'precision': precision,\n","        'recall': recall,\n","        'f1_score': f1,\n","        'accuracy': accuracy,\n","        'specificity': specificity,\n","        'sensitivity': sensitivity,\n","        'false negativo': fn\n","    }\n","\n","    return metrics\n","\n","\n","\n","\n","\n","model_path = f'C:/Users/Lucas/PIBIC/model_pytorch_/{label_model}.pth'\n","\n","if label_model[:7] == \"ResNet1\":\n","    model_kernel = ResNet101()\n","\n","elif label_model[:7] == \"ResNet5\":\n","    model_kernel = ResNet50()\n","\n","elif label_model[:14] == \"EfficientNetB0\":\n","    model_kernel = EfficientNetB0()\n","    \n","elif label_model[:14] == \"EfficientNetB4\":\n","    model_kernel = EfficientNetB4()\n","\n","elif label_model[:14] == \"EfficientNetB7\":\n","    model_kernel = EfficientNetB7()\n","\n","elif label_model[:5] == \"VGG16\":\n","    model_kernel = VGG16()\n","\n","\n","model_kernel.load_state_dict(torch.load(model_path))\n","model_kernel.to(device)  # Move the model to the specified device\n","model_kernel.eval()  # Set the model to evaluation mode\n","\n","# Call the function with plot_images=True to plot images\n","metrics = calculate_metrics(model_kernel, test_dataset, device, plot_images=True)\n","metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.DataFrame(metrics.items(), columns=['Metric', 'Value']).to_csv(f'C:/Users/Lucas/PIBIC/model_pytorch_/metrics/{label_model}.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_images(model, test_dataset, device, plot_images=False, num_images_to_plot=10):\n","    # Initialize variables to store predictions and ground truth\n","    y_pred = []\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","    images_plotted = 0  # Counter for the number of images plotted\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_pred.extend(predictions)\n","\n","            # Plot images with true and predicted labels\n","            if plot_images and images_plotted < num_images_to_plot:\n","                plot_image(images, labels, predictions)\n","                images_plotted += 1\n","\n","            # Break the loop if the desired number of images is plotted\n","            if images_plotted >= num_images_to_plot:\n","                break\n","\n","\n","def plot_image(images, true_label, predicted_label):\n","    if len(images.shape) == 4 and images.shape[1] == 3:\n","        # Convert CUDA tensor to numpy array and rearrange dimensions for RGB image\n","        images = images.cpu().detach().numpy().squeeze().transpose((1, 2, 0))\n","    else:\n","        # Convert CUDA tensor to numpy array and squeeze if necessary\n","        images = images.cpu().detach().numpy().squeeze()\n","\n","    if len(images.shape) == 2:\n","        plt.imshow(images, cmap='gray')\n","    else:\n","        plt.imshow(images)\n","    \n","    # Format the labels\n","    true_label = true_label.item() if isinstance(true_label, torch.Tensor) else true_label\n","    predicted_label = predicted_label.item() if isinstance(predicted_label, torch.Tensor) else predicted_label\n","    \n","    plt.title(f'True label: {true_label}; Predicted: {predicted_label}')\n","    plt.show()\n","    \n","    \n","process_images(model_kernel, test_dataset, device, plot_images=True)"]},{"cell_type":"markdown","metadata":{},"source":["**Sugestão de Próximos Passos**\n","\n","1. Colocar para salvar o modelo com a menor validation loss.\n","2. Colocar código para carregar o modelo salvo e fazer predições em imagens do dataset.\n","3. Criar métricas de acurácia (Accuracy, Precision, Recall, F-score, etc.) para avaliar o dataset de teste com o modelo salvo.\n","\n","Quando tudo estiver pronto:\n","4. Criar novos modelos CNN (começar pela ResNet101).\n","5. Implementar outros modelos.\n","\n","Quando estiver pronto:\n","6. Implementar no seu dataset.\n"]},{"cell_type":"markdown","metadata":{},"source":["Para binário tem que mudar a loss (CrossEntropy), a sigmoid da layer final para softmax"]},{"cell_type":"markdown","metadata":{},"source":["# Materiais e Métodos\n","\n","## 1. Datasets\n","\n","Explicação sobre os conjuntos de dados utilizados.\n","\n","## 2. Modelos\n","\n","Explicação sobre como funciona um modelo CNN (Convolutional Neural Network) e os parâmetros utilizados.\n","\n","### 2.1. EfficientNet\n","\n","### 2.2. ResNet101\n","\n","...\n","\n","## 3. Métricas\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
