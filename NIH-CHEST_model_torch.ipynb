{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:05:11.118554Z","iopub.status.busy":"2022-01-02T01:05:11.117796Z","iopub.status.idle":"2022-01-02T01:05:13.680413Z","shell.execute_reply":"2022-01-02T01:05:13.679697Z","shell.execute_reply.started":"2022-01-02T01:05:11.118516Z"},"trusted":true},"outputs":[],"source":["import os  \n","import glob\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from sklearn.metrics import multilabel_confusion_matrix\n","\n","\n","import PIL \n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt \n","\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from efficientnet_pytorch import EfficientNet\n","from torchinfo import summary \n","\n","import torch.optim as optim\n","from IPython.display import Image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import transforms\n","import torch.nn.functional as F\n","\n","import pydicom\n","from PIL import Image\n","\n","import cv2"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:05:26.643276Z","iopub.status.busy":"2022-01-02T01:05:26.643017Z","iopub.status.idle":"2022-01-02T01:05:26.689544Z","shell.execute_reply":"2022-01-02T01:05:26.688904Z","shell.execute_reply.started":"2022-01-02T01:05:26.643247Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device "]},{"cell_type":"markdown","metadata":{},"source":["Set Random Seed for reproducability"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:07:17.417698Z","iopub.status.busy":"2022-01-02T01:07:17.417439Z","iopub.status.idle":"2022-01-02T01:07:17.425362Z","shell.execute_reply":"2022-01-02T01:07:17.424534Z","shell.execute_reply.started":"2022-01-02T01:07:17.417671Z"},"trusted":true},"outputs":[],"source":["random_seed = 124\n","np.random.seed(random_seed)\n","\n","torch.manual_seed(random_seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["train_df = pd.read_csv('C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/train_df.csv')\n","test_df = pd.read_csv('C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/test_df.csv')\n","valid_df = pd.read_csv('C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/valid_df.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["train_df = train_df[['Image Index', 'Finding Labels', 'Path Image']]\n","test_df = test_df[['Image Index', 'Finding Labels', 'Path Image']]\n","valid_df = valid_df[['Image Index', 'Finding Labels', 'Path Image']]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["labels = ['No Finding', 'Infiltration', 'Atelectasis', 'Effusion', 'Nodule', 'Pneumothorax', 'Mass']\n","labels_dict = {'No Finding': 0, 'Infiltration': 1, 'Atelectasis': 2, 'Effusion': 3, 'Nodule': 4, 'Pneumothorax': 5, 'Mass': 6}"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["train_path = list(train_df['Path Image'])\n","test_path = list(test_df['Path Image'])\n","valid_path = list(valid_df['Path Image'])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["train_label = [labels_dict[item] if item in labels_dict else item for item in list(train_df['Finding Labels'])]\n","test_label = [labels_dict[item] if item in labels_dict else item for item in list(test_df['Finding Labels'])]\n","valid_label = [labels_dict[item] if item in labels_dict else item for item in list(valid_df['Finding Labels'])]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["1500"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["sum(valid_df['Finding Labels'] == labels[0])"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","True\n","True\n","True\n","True\n","True\n","True\n"]}],"source":["df = pd.DataFrame(train_label)\n","\n","for i in range(0,len(labels),1):\n","    print(sum(train_df['Finding Labels'] == labels[i]) ==  sum(df[0] == i))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["7"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(labels)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["(list, list, list)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["type(train_label), type(test_label), type(valid_label)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image Index</th>\n","      <th>Finding Labels</th>\n","      <th>Path Image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00000005_006.png</td>\n","      <td>Infiltration</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Image Index Finding Labels  \\\n","0  00000005_006.png   Infiltration   \n","\n","                                          Path Image  \n","0  C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head(1)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["[1, 1, 1, 1, 1]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train_label[:5]"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset Class\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:06:32.906034Z","iopub.status.busy":"2022-01-02T02:06:32.905735Z","iopub.status.idle":"2022-01-02T02:06:32.915082Z","shell.execute_reply":"2022-01-02T02:06:32.914103Z","shell.execute_reply.started":"2022-01-02T02:06:32.906002Z"},"trusted":true},"outputs":[],"source":["class CT_Dataset(Dataset):\n","    def __init__(self, img_path, img_labels, img_transforms=None, grayscale=False):\n","        self.img_path = img_path\n","        self.img_labels = torch.Tensor(img_labels)\n","        if (img_transforms is None) & (grayscale == True):\n","            self.transforms = transforms.Compose([transforms.Grayscale(),\n","                                                  transforms.Resize((250, 250)),\n","                                                  transforms.ToTensor()])\n","        elif grayscale == False:\n","            self.transforms = transforms.Compose([transforms.Resize((250, 250)),\n","                                                  transforms.ToTensor()])\n","        else:\n","            self.transforms = img_transforms\n","    \n","    def __getitem__(self, index):\n","        # load image\n","        cur_path = self.img_path[index]\n","        cur_img = PIL.Image.open(cur_path).convert('RGB')\n","        cur_img = self.transforms(cur_img)\n","\n","        return cur_img, self.img_labels[index]\n","    \n","    def __len__(self):\n","        return len(self.img_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Model Development"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet50"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["\n","class ResNet50(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet50, self).__init__()\n","        self.resnet50 = models.resnet50(pretrained=True)\n","        in_features = self.resnet50.fc.in_features\n","        self.resnet50.fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.resnet50(x)\n","    \n","    def get_name(self):\n","        return 'ResNet50'\n"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet101"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["class ResNet101(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet101, self).__init__()\n","        self.resnet101 = models.resnet101(pretrained=True)\n","        in_features = self.resnet101.fc.in_features\n","        self.resnet101.fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.resnet101(x)\n","    \n","    def get_name(self):\n","        return 'ResNet101'\n"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB0"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["class EfficientNetB0(nn.Module):\n","    def __init__(self, num_classes):\n","        super(EfficientNetB0, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b0')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n","    \n","    def get_name(self):\n","        return 'EfficientNetB0'\n"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB4"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["class EfficientNetB4(nn.Module):\n","    def __init__(self, num_classes):\n","        super(EfficientNetB4, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b4')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n","    \n","    def get_name(self):\n","        return 'EfficientNetB4'"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB7"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["class EfficientNetB7(nn.Module):\n","    def __init__(self, num_classes):\n","        super(EfficientNetB7, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b7')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n","    \n","    def get_name(self):\n","        return 'EfficientNetB7'"]},{"cell_type":"markdown","metadata":{},"source":["### VGG16"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["class VGG16(nn.Module):\n","    def __init__(self, num_classes):\n","        super(VGG16, self).__init__()\n","        self.vgg16 = models.vgg16(pretrained=True)\n","        in_features = self.vgg16.classifier[6].in_features\n","        self.vgg16.classifier[6] = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.vgg16(x)\n","    \n","    def get_name(self):\n","        return 'VGG16'"]},{"cell_type":"markdown","metadata":{},"source":["### Function train_model"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["{'No Finding': 15000,\n"," 'Infiltration': 9547,\n"," 'Atelectasis': 4215,\n"," 'Effusion': 3955,\n"," 'Nodule': 2705,\n"," 'Pneumothorax': 2194,\n"," 'Mass': 2139}"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["result_df = pd.read_csv('C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/result_df.csv')\n","qnt_labels = result_df['Finding Labels'].value_counts()\n","qnt_images_each_label = qnt_labels.to_dict()\n","qnt_images_each_label"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["total_samples = 0\n","for value in qnt_images_each_label.values():\n","    total_samples += value"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["9547"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["qnt_images_each_label['Infiltration']"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["['No Finding',\n"," 'Infiltration',\n"," 'Atelectasis',\n"," 'Effusion',\n"," 'Nodule',\n"," 'Pneumothorax',\n"," 'Mass']"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["labels"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["[0.37861904761904763,\n"," 0.5948764757814721,\n"," 1.3473987459752583,\n"," 1.4359761603756547,\n"," 2.0995510958542383,\n"," 2.5885531970308633,\n"," 2.6551125358979495]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["num_classes = len(train_df['Finding Labels'].unique())\n","\n","weight_No_Finding = total_samples/(qnt_images_each_label['No Finding'] * num_classes)\n","weight_Infiltration = total_samples/( qnt_images_each_label['Infiltration'] * num_classes)\n","weight_Atelectasis = total_samples/( qnt_images_each_label['Atelectasis'] * num_classes)\n","weight_Effusion = total_samples/( qnt_images_each_label['Effusion'] * num_classes)\n","weight_Nodule = total_samples/( qnt_images_each_label['Nodule'] * num_classes)\n","weight_Pneumothorax = total_samples/( qnt_images_each_label['Pneumothorax'] * num_classes)\n","weight_Mass = total_samples/( qnt_images_each_label['Mass'] * num_classes)\n","\n","weights = [weight_No_Finding, weight_Infiltration, weight_Atelectasis, weight_Effusion, weight_Nodule, weight_Pneumothorax, weight_Mass]\n","weights"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:38:15.316255Z","iopub.status.busy":"2022-01-02T02:38:15.315802Z","iopub.status.idle":"2022-01-02T02:38:15.333659Z","shell.execute_reply":"2022-01-02T02:38:15.332954Z","shell.execute_reply.started":"2022-01-02T02:38:15.316218Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","# Define the training function\n","def train_model(model, train_dataset, val_dataset, test_dataset, device, path_save_model, \n","                lr=0.0001, epochs=30, batch_size=32, l2=0.00001, gamma=0.5,\n","                patience=7):\n","    model = model.to(device)\n","\n","    # Construct dataloader\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    # History\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n","\n","    weight = torch.tensor(weights).to(device)\n","    \n","    # Set up loss function and optimizer\n","    criterion = nn.CrossEntropyLoss(weight=weight)  \n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=patience, gamma=gamma)\n","\n","    # Initialize variables to track the best validation loss and corresponding model state\n","    best_val_loss = float('inf')\n","    best_model_state = None\n","\n","    # Training Loop\n","    print(\"Training Start:\")\n","    for epoch in range(epochs):\n","        model.train()\n","\n","        train_loss = 0\n","        train_acc = 0\n","        val_loss = 0\n","        val_acc = 0\n","\n","        for i, (images, labels) in enumerate(train_loader):\n","            images = images.to(device)\n","            labels = labels.to(device).long()   # Convert labels to Long data type\n","\n","            outputs = model(images).float()  # Make sure the output is of type float\n","            pred = outputs.argmax(dim=1)  ####################################################\n","            # print(f'Pred\\n{pred}')\n","            # print(f'labels\\n{labels}')\n","            # print(f'outputs\\n{outputs}')\n","            cur_train_loss = criterion(outputs, labels)\n","            # pred = torch.nn.functional.one_hot(pred, num_classes=num_classes).cpu().numpy()\n","\n","            cur_train_acc = (pred == labels).sum().item() / batch_size\n","\n","            cur_train_loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            train_loss += cur_train_loss \n","            train_acc += cur_train_acc\n","        \n","        model.eval()\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images = images.to(device)\n","                labels = labels.to(device).long()   # Convert labels to Long data type\n","\n","                outputs = model(images).float()  # Make sure the output is of type float\n","\n","                cur_valid_loss = criterion(outputs, labels)\n","                val_loss += cur_valid_loss\n","\n","                pred = outputs.argmax(dim=1)  ####################################################\n","                # pred = torch.nn.functional.one_hot(pred, num_classes=num_classes).cpu().numpy()\n","                val_acc += (pred == labels).sum().item() / batch_size\n","\n","        scheduler.step()\n","\n","        train_loss = train_loss / len(train_loader)\n","        train_acc = train_acc / len(train_loader)\n","        val_loss = val_loss / len(val_loader)\n","        val_acc = val_acc / len(val_loader)\n","\n","        print(f\"Epoch:{epoch + 1} / {epochs}, lr: {optimizer.param_groups[0]['lr']:.5f} train loss:{train_loss:.5f}, train acc: {train_acc:.5f}, valid loss:{val_loss:.5f}, valid acc:{val_acc:.5f}\")\n","    \n","        history['train_loss'].append(train_loss)\n","        history['train_acc'].append(train_acc)\n","        history['val_loss'].append(val_loss)\n","        history['val_acc'].append(val_acc)\n","    \n","        # Update the best model if validation loss is the lowest so far\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            best_model_state = model.state_dict()\n","\n","    # Load the best model state\n","    if best_model_state is not None:\n","        model.load_state_dict(best_model_state)\n","\n","    test_acc = 0\n","    print(f'The best val loss is {best_val_loss}.\\n\\n')\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device).long()   # Convert labels to Long data type\n","\n","            outputs = model(images).float()  # Make sure the output is of type float\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predictions)\n","            pred = outputs.argmax(dim=1)  ####################################################\n","            # pred = torch.nn.functional.one_hot(pred, num_classes=num_classes).cpu().numpy()\n","            test_acc += (pred == labels).sum().item()\n","\n","    y_true = np.array(y_true)\n","    y_pred = np.array(pred)\n","    \n","        # Calculate evaluation metrics\n","    accuracy = (test_acc / len(test_loader))\n","    tn, fp, fn, tp = multilabel_confusion_matrix(y_true, y_pred).ravel()\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","    specificity = tn / (tn + fp)\n","    sensitivity = tp / (fn + tp)\n","\n","    metrics = {\n","        'precision': precision,\n","        'recall': recall,\n","        'f1_score': f1,\n","        'accuracy': accuracy,\n","        'specificity': specificity,\n","        'sensitivity': sensitivity,\n","        'Best Value Loss': best_val_loss,\n","        'false negativo': fn\n","    }\n","    \n","    dataset = pd.DataFrame(metrics.items(), columns=['Metric', 'Value']).to_csv(f'{path_save_model}.csv')\n","    print(f'Test Accuracy:  {accuracy}\\n')\n","    print(f'Metrics:  {metrics}\\n')\n","\n","    return history, model\n"]},{"cell_type":"markdown","metadata":{},"source":["Process the datasets and train the model"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Current GPU memory usage: 0.0 MB\n","Max GPU memory usage: 0.0 MB\n"]}],"source":["print(\"Current GPU memory usage:\", torch.cuda.memory_allocated() / (1024 ** 2), \"MB\")\n","print(\"Max GPU memory usage:\", torch.cuda.max_memory_allocated() / (1024 ** 2), \"MB\")\n","\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["(31803, 31803)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["len(train_path), len(train_label)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["train_dataset = CT_Dataset(img_path=train_path, img_labels=np.array(train_label))\n","val_dataset = CT_Dataset(img_path=valid_path, img_labels=np.array(valid_label))\n","test_dataset = CT_Dataset(img_path=test_path, img_labels=np.array(test_label))"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:40:25.322238Z","iopub.status.busy":"2022-01-02T02:40:25.321990Z","iopub.status.idle":"2022-01-02T02:42:57.004380Z","shell.execute_reply":"2022-01-02T02:42:57.003631Z","shell.execute_reply.started":"2022-01-02T02:40:25.322210Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","c:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["Training Start:\n","Epoch:1 / 50, lr: 0.00020 train loss:1.92998, train acc: 0.15565, valid loss:1.94730, valid acc:0.09900\n","Epoch:2 / 50, lr: 0.00020 train loss:1.94592, train acc: 0.10532, valid loss:1.94027, valid acc:0.37500\n","Epoch:3 / 50, lr: 0.00020 train loss:1.94574, train acc: 0.37726, valid loss:1.93772, valid acc:0.37500\n","Epoch:4 / 50, lr: 0.00020 train loss:1.94568, train acc: 0.37726, valid loss:1.93658, valid acc:0.37500\n","Epoch:5 / 50, lr: 0.00010 train loss:1.94564, train acc: 0.37726, valid loss:1.93501, valid acc:0.37500\n","Epoch:6 / 50, lr: 0.00010 train loss:1.94563, train acc: 0.37726, valid loss:1.93505, valid acc:0.37500\n","Epoch:7 / 50, lr: 0.00010 train loss:1.94568, train acc: 0.35620, valid loss:1.93510, valid acc:0.37500\n","Epoch:8 / 50, lr: 0.00010 train loss:1.94563, train acc: 0.37726, valid loss:1.93489, valid acc:0.37500\n","Epoch:9 / 50, lr: 0.00010 train loss:1.94566, train acc: 0.37726, valid loss:1.93490, valid acc:0.37500\n","Epoch:10 / 50, lr: 0.00005 train loss:1.94560, train acc: 0.37726, valid loss:1.93436, valid acc:0.37500\n","Epoch:11 / 50, lr: 0.00005 train loss:1.94559, train acc: 0.37726, valid loss:1.93432, valid acc:0.37500\n","Epoch:12 / 50, lr: 0.00005 train loss:1.94563, train acc: 0.37726, valid loss:1.93439, valid acc:0.37500\n","Epoch:13 / 50, lr: 0.00005 train loss:1.94562, train acc: 0.37726, valid loss:1.93449, valid acc:0.37500\n","Epoch:14 / 50, lr: 0.00005 train loss:1.94564, train acc: 0.37726, valid loss:1.93462, valid acc:0.37500\n","Epoch:15 / 50, lr: 0.00003 train loss:1.94563, train acc: 0.37726, valid loss:1.93452, valid acc:0.37500\n","Epoch:16 / 50, lr: 0.00003 train loss:1.94561, train acc: 0.37726, valid loss:1.93450, valid acc:0.37500\n","Epoch:17 / 50, lr: 0.00003 train loss:1.94564, train acc: 0.37726, valid loss:1.93459, valid acc:0.37500\n","Epoch:18 / 50, lr: 0.00003 train loss:1.94558, train acc: 0.37726, valid loss:1.93449, valid acc:0.37500\n","Epoch:19 / 50, lr: 0.00003 train loss:1.94563, train acc: 0.37726, valid loss:1.93456, valid acc:0.37500\n","Epoch:20 / 50, lr: 0.00001 train loss:1.94562, train acc: 0.37726, valid loss:1.93463, valid acc:0.37500\n","Epoch:21 / 50, lr: 0.00001 train loss:1.94560, train acc: 0.37726, valid loss:1.93462, valid acc:0.37500\n","Epoch:22 / 50, lr: 0.00001 train loss:1.94561, train acc: 0.37726, valid loss:1.93461, valid acc:0.37500\n","Epoch:23 / 50, lr: 0.00001 train loss:1.94561, train acc: 0.37726, valid loss:1.93461, valid acc:0.37500\n","Epoch:24 / 50, lr: 0.00001 train loss:1.94562, train acc: 0.37726, valid loss:1.93463, valid acc:0.37500\n","Epoch:25 / 50, lr: 0.00001 train loss:1.94562, train acc: 0.37726, valid loss:1.93462, valid acc:0.37500\n","Epoch:26 / 50, lr: 0.00001 train loss:1.94559, train acc: 0.37726, valid loss:1.93462, valid acc:0.37500\n","Epoch:27 / 50, lr: 0.00001 train loss:1.94560, train acc: 0.37726, valid loss:1.93463, valid acc:0.37500\n","Epoch:28 / 50, lr: 0.00001 train loss:1.94564, train acc: 0.37726, valid loss:1.93464, valid acc:0.37500\n","Epoch:29 / 50, lr: 0.00001 train loss:1.94559, train acc: 0.37726, valid loss:1.93464, valid acc:0.37500\n","Epoch:30 / 50, lr: 0.00000 train loss:1.94561, train acc: 0.37726, valid loss:1.93464, valid acc:0.37500\n","Epoch:31 / 50, lr: 0.00000 train loss:1.94564, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:32 / 50, lr: 0.00000 train loss:1.94563, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:33 / 50, lr: 0.00000 train loss:1.94563, train acc: 0.37726, valid loss:1.93466, valid acc:0.37500\n","Epoch:34 / 50, lr: 0.00000 train loss:1.94561, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:35 / 50, lr: 0.00000 train loss:1.94559, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:36 / 50, lr: 0.00000 train loss:1.94558, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:37 / 50, lr: 0.00000 train loss:1.94558, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:38 / 50, lr: 0.00000 train loss:1.94561, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:39 / 50, lr: 0.00000 train loss:1.94562, train acc: 0.37726, valid loss:1.93464, valid acc:0.37500\n","Epoch:40 / 50, lr: 0.00000 train loss:1.94562, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:41 / 50, lr: 0.00000 train loss:1.94558, train acc: 0.37726, valid loss:1.93464, valid acc:0.37500\n","Epoch:42 / 50, lr: 0.00000 train loss:1.94555, train acc: 0.37726, valid loss:1.93464, valid acc:0.37500\n","Epoch:43 / 50, lr: 0.00000 train loss:1.94563, train acc: 0.37726, valid loss:1.93464, valid acc:0.37500\n","Epoch:44 / 50, lr: 0.00000 train loss:1.94561, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:45 / 50, lr: 0.00000 train loss:1.94561, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:46 / 50, lr: 0.00000 train loss:1.94559, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:47 / 50, lr: 0.00000 train loss:1.94562, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:48 / 50, lr: 0.00000 train loss:1.94563, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:49 / 50, lr: 0.00000 train loss:1.94564, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","Epoch:50 / 50, lr: 0.00000 train loss:1.94558, train acc: 0.37726, valid loss:1.93465, valid acc:0.37500\n","The best val loss is 1.934320330619812.\n","\n","\n"]},{"ename":"ValueError","evalue":"Classification metrics can't handle a mix of multiclass and multilabel-indicator targets","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Lucas\\PIBIC\\NIH-CHEST_model_torch.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# model_kernel = ResNet101(num_classes=7)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# model_kernel = EfficientNetB(num_classes=7)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# model_kernel = EfficientNetB4(num_classes=7)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# model_kernel = EfficientNetB7(num_classes=7)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# model_kernel = VGG16(num_classes=7)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m path_save_model \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/model_/\u001b[39m\u001b[39m{\u001b[39;00mmodel_kernel\u001b[39m.\u001b[39mget_name()\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m hist_kernel, model_kernel \u001b[39m=\u001b[39m train_model(model_kernel, train_dataset, val_dataset, test_dataset, device, path_save_model, lr\u001b[39m=\u001b[39;49m\u001b[39m0.0002\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m batch_size, epochs\u001b[39m=\u001b[39;49mepoch, l2\u001b[39m=\u001b[39;49m\u001b[39m0.09\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n","\u001b[1;32mc:\\Users\\Lucas\\PIBIC\\NIH-CHEST_model_torch.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m     \u001b[39m# Calculate evaluation metrics\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m accuracy \u001b[39m=\u001b[39m (test_acc \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(test_loader))\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m tn, fp, fn, tp \u001b[39m=\u001b[39m confusion_matrix(y_true, y_pred)\u001b[39m.\u001b[39mravel()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m precision \u001b[39m=\u001b[39m precision_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X61sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m recall \u001b[39m=\u001b[39m recall_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\metrics\\_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m    232\u001b[0m     {\n\u001b[0;32m    233\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m ):\n\u001b[0;32m    244\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    328\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n","\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and multilabel-indicator targets"]}],"source":["batch_size = 32\n","epoch = 50\n","\n","\n","# Train the ResNet101 model\n","model_kernel = ResNet50(num_classes=7)\n","# model_kernel = ResNet101(num_classes=7)\n","# model_kernel = EfficientNetB(num_classes=7)\n","# model_kernel = EfficientNetB4(num_classes=7)\n","# model_kernel = EfficientNetB7(num_classes=7)\n","# model_kernel = VGG16(num_classes=7)\n","\n","\n","\n","\n","path_save_model = f'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/model_/{model_kernel.get_name()}_{epoch}'\n","hist_kernel, model_kernel = train_model(model_kernel, train_dataset, val_dataset, test_dataset, device, path_save_model, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["56165dvsdvds"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["pred = torch.tensor([5, 5, 3, 5, 5, 5, 1, 2, 5, 5, 1, 2, 1, 5, 5, 2, 5, 2, 5, 2, 5, 5, 5, 5,\n","        5, 5, 5, 5, 2, 2, 5, 5], device='cuda:0')\n","labels = torch.tensor([1., 0., 0., 1., 2., 5., 1., 0., 1., 0., 2., 6., 4., 1., 4., 1., 0., 1.,\n","        1., 4., 0., 0., 3., 1., 1., 0., 3., 0., 4., 0., 3., 1.],\n","       device='cuda:0')\n","outputs = torch.tensor([[ 0.1039,  0.0196,  0.1340, -0.0606, -0.0624, -0.1492,  0.1489],\n","        [ 0.1638,  0.2615,  0.1425, -0.0664, -0.0220, -0.1176, -0.0086],\n","        [ 0.0499,  0.1659,  0.0624, -0.1114, -0.0556, -0.0509,  0.0630],\n","        [ 0.2102,  0.1398,  0.1844, -0.1581, -0.1947, -0.1324, -0.0041],\n","        [ 0.1990,  0.1115,  0.0485, -0.0643, -0.0910, -0.1942,  0.0245],\n","        [ 0.1179, -0.0302,  0.0422, -0.0449, -0.1007, -0.0709, -0.0055],\n","        [ 0.1428,  0.0111,  0.1842, -0.0272, -0.0348, -0.0723,  0.0479],\n","        [ 0.3330,  0.0644, -0.0239, -0.0471, -0.0416, -0.0922, -0.0870],\n","        [ 0.1566,  0.0252,  0.0238,  0.0467, -0.1089, -0.1529,  0.1591],\n","        [ 0.2148,  0.2172,  0.1216, -0.0358, -0.1598, -0.0973, -0.0901],\n","        [ 0.1118,  0.1927,  0.0710, -0.0861, -0.0437, -0.1435,  0.1106],\n","        [ 0.2535,  0.1214,  0.1725, -0.0893, -0.0666, -0.0366, -0.0411],\n","        [ 0.0763,  0.1014,  0.1511, -0.0185, -0.1423, -0.0700, -0.0263],\n","        [ 0.0939,  0.0642,  0.1573, -0.1136, -0.0953, -0.1442, -0.0850],\n","        [ 0.1151,  0.1056,  0.0030, -0.0148, -0.0330, -0.1542, -0.0428],\n","        [ 0.1255,  0.0819,  0.2538, -0.1424,  0.0214, -0.2399, -0.0481],\n","        [ 0.1598,  0.1540,  0.1070, -0.0325, -0.0415, -0.0631,  0.0029],\n","        [ 0.1825,  0.0751, -0.0437, -0.0999, -0.1244, -0.1818,  0.1489],\n","        [ 0.0868,  0.2163,  0.0354, -0.1322, -0.1326, -0.2135,  0.1156],\n","        [ 0.1741,  0.1908,  0.0927, -0.0541,  0.0426, -0.1062, -0.0114],\n","        [ 0.1124,  0.1096,  0.0362, -0.0808, -0.1658, -0.0545, -0.0318],\n","        [ 0.0577,  0.3386,  0.1067, -0.1172,  0.0819, -0.1923, -0.0056],\n","        [ 0.1731,  0.0573,  0.1518, -0.1144, -0.1122, -0.2052,  0.0473],\n","        [ 0.2782,  0.1307, -0.0476, -0.0025, -0.1064, -0.1131,  0.0086],\n","        [ 0.0075,  0.1485, -0.0037, -0.0975, -0.1250, -0.1801,  0.0208],\n","        [ 0.1043,  0.0389,  0.0586, -0.0291, -0.0548, -0.0643,  0.0337],\n","        [ 0.2485,  0.1398, -0.0677,  0.0053, -0.0031, -0.0763,  0.0114],\n","        [ 0.1488,  0.1722,  0.1780, -0.0195,  0.0364, -0.0952, -0.0126],\n","        [ 0.1048,  0.2050,  0.1818, -0.1468, -0.1223, -0.1630,  0.0551],\n","        [ 0.2036,  0.1393,  0.0089, -0.0018, -0.0506, -0.1196, -0.0014],\n","        [ 0.1451,  0.1543,  0.1173, -0.0693, -0.0077, -0.1841,  0.1808],\n","        [ 0.0967,  0.1962,  0.0779, -0.0615, -0.0854, -0.1139, -0.0776]],\n","       device='cuda:0')"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","# predictions"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[],"source":["y_pred = np.array(pred.cpu().numpy())\n","# y_pred"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":["y_true = np.array(labels.cpu().numpy())\n","y_pred = np.array(pred.cpu().numpy())"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"data":{"text/plain":["((32,), (32,))"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["y_true.shape, y_pred.shape"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"data":{"text/plain":["array([[[22,  0],\n","        [10,  0]],\n","\n","       [[19,  2],\n","        [10,  1]],\n","\n","       [[23,  7],\n","        [ 2,  0]],\n","\n","       [[28,  1],\n","        [ 3,  0]],\n","\n","       [[28,  0],\n","        [ 4,  0]],\n","\n","       [[11, 20],\n","        [ 0,  1]],\n","\n","       [[31,  0],\n","        [ 1,  0]]], dtype=int64)"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","from sklearn.metrics import multilabel_confusion_matrix\n","# y_true = np.array([[1, 0, 1],\n","#                    [0, 1, 0]])\n","# y_pred = np.array([[1, 0, 0],\n","#                    [0, 1, 1]])\n","multilabel_confusion_matrix(y_true, y_pred)"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","f1 = f1_score(y_true, y_pred, average='weighted')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# hist_kernel = hist_ResNet50\n","# model_kernel = model_ResNet50\n","label_model = model_kernel._get_name()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save(model_kernel.state_dict(), f'{path_save_model}.pth')"]},{"cell_type":"markdown","metadata":{},"source":["## Metricis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_metrics(hist, label_model) :\n","    # plot training curves\n","    epochs = range(1, len(hist['train_loss']) + 1)\n","\n","    train_loss = [t.cpu().detach().numpy() for t in hist['train_loss']]\n","    val_loss = [t.cpu().detach().numpy() for t in hist['val_loss']]\n","\n","\n","    fig, ax = plt.subplots(1,2, figsize=(20,6))\n","    ax[0].plot(epochs, train_loss, 'r-', label='Train')\n","    ax[0].plot(epochs, val_loss, 'b-', label='Evaluation')\n","    ax[0].set_title('Loss')\n","    ax[0].set_xlabel('Epochs')\n","    ax[0].set_ylabel('Loss')\n","    ax[0].legend()\n","    plt.savefig(f'{path_save_model}.png')  # This saves the plot as a PNG image\n","\n","    ax[1].plot(epochs, hist['train_acc'], 'r-', label='Train')\n","    ax[1].plot(epochs, hist['val_acc'], 'b-', label='Evaluation')\n","    ax[1].set_title('Accuracy')\n","    ax[1].set_xlabel('Epochs')\n","    ax[1].set_ylabel('Acc')\n","    ax[1].legend()\n","    plt.savefig(f'{path_save_model}.png')  # This saves the plot as a PNG image\n","    \n","\n","    plt.show()\n","    \n","    \n","plot_metrics(hist_kernel, label_model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calculate_metrics(model, test_dataset, device, plot_images=False):\n","    # Initialize variables to store predictions and ground truth\n","    y_true = []\n","    y_pred = []\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    cont = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predictions)\n","            cont+=1\n","            if cont == 5:\n","                break\n","\n","    # Convert lists to numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","\n","    return y_true, y_pred\n","\n","\n","\n","y_true, y_pred = calculate_metrics(model_kernel, test_dataset, device, plot_images=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import multilabel_confusion_matrix, precision_score, accuracy_score, recall_score, f1_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_true, y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cm_matrix = confusion_matrix(y_true, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate evaluation metrics\n","cm_matrix = multilabel_confusion_matrix(y_true, y_pred).ravel()\n","precision = precision_score(y_true, y_pred, average='weighted')\n","accuracy = accuracy_score(y_true, y_pred)\n","recall = recall_score(y_true, y_pred, average='weighted')\n","f1 = f1_score(y_true, y_pred, average='weighted')\n","specificity = tn / (tn + fp)\n","sensitivity = tp / (fn + tp)\n","\n","metrics = {\n","    'precision': precision,\n","    'recall': recall,\n","    'f1_score': f1,\n","    'accuracy': accuracy,\n","    'specificity': specificity,\n","    'sensitivity': sensitivity,\n","    'false negativo': fn\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calculate_metrics(model, test_dataset, device, plot_images=False):\n","    # Initialize variables to store predictions and ground truth\n","    y_true = []\n","    y_pred = []\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    cont = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predictions)\n","            cont+=1\n","            if cont == 5:\n","                break\n","\n","    # Convert lists to numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","    # Calculate evaluation metrics\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    accuracy = accuracy_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","    specificity = tn / (tn + fp)\n","    sensitivity = tp / (fn + tp)\n","\n","    metrics = {\n","        'precision': precision,\n","        'recall': recall,\n","        'f1_score': f1,\n","        'accuracy': accuracy,\n","        'specificity': specificity,\n","        'sensitivity': sensitivity,\n","        'false negativo': fn\n","    }\n","\n","    return metrics\n","\n","\n","\n","model_path = f'{path_save_model}.pth'\n","\n","if label_model[:7] == \"ResNet1\":\n","    model_kernel = ResNet101(num_classes=7)\n","\n","elif label_model[:7] == \"ResNet5\":\n","    model_kernel = ResNet50(num_classes=7)\n","\n","elif label_model[:14] == \"EfficientNetB0\":\n","    model_kernel = EfficientNetB0(num_classes=7)\n","    \n","elif label_model[:14] == \"EfficientNetB4\":\n","    model_kernel = EfficientNetB4(num_classes=7)\n","\n","elif label_model[:14] == \"EfficientNetB7\":\n","    model_kernel = EfficientNetB7(num_classes=7)\n","\n","elif label_model[:5] == \"VGG16\":\n","    model_kernel = VGG16(num_classes=7)\n","\n","\n","model_kernel.load_state_dict(torch.load(model_path))\n","model_kernel.to(device)  # Move the model to the specified device\n","model_kernel.eval()  # Set the model to evaluation mode\n","\n","# Call the function with plot_images=True to plot images\n","metrics = calculate_metrics(model_kernel, test_dataset, device, plot_images=True)\n","metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n","y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n","multilabel_confusion_matrix(y_true, y_pred)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.DataFrame(metrics.items(), columns=['Metric', 'Value']).to_csv(f'{path_save_model}.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_images(model, test_dataset, device, plot_images=False, num_images_to_plot=10):\n","    # Initialize variables to store predictions and ground truth\n","    y_pred = []\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","    images_plotted = 0  # Counter for the number of images plotted\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_pred.extend(predictions)\n","\n","            # Plot images with true and predicted labels\n","            if plot_images and images_plotted < num_images_to_plot:\n","                plot_image(images, labels, predictions)\n","                images_plotted += 1\n","\n","            # Break the loop if the desired number of images is plotted\n","            if images_plotted >= num_images_to_plot:\n","                break\n","\n","\n","def plot_image(images, true_label, predicted_label):\n","    if len(images.shape) == 4 and images.shape[1] == 3:\n","        # Convert CUDA tensor to numpy array and rearrange dimensions for RGB image\n","        images = images.cpu().detach().numpy().squeeze().transpose((1, 2, 0))\n","    else:\n","        # Convert CUDA tensor to numpy array and squeeze if necessary\n","        images = images.cpu().detach().numpy().squeeze()\n","\n","    if len(images.shape) == 2:\n","        plt.imshow(images, cmap='gray')\n","    else:\n","        plt.imshow(images)\n","    \n","    # Format the labels\n","    true_label = true_label.item() if isinstance(true_label, torch.Tensor) else true_label\n","    predicted_label = predicted_label.item() if isinstance(predicted_label, torch.Tensor) else predicted_label\n","    \n","    plt.title(f'True label: {true_label}; Predicted: {predicted_label}')\n","    plt.show()\n","    \n","    \n","process_images(model_kernel, test_dataset, device, plot_images=True)"]},{"cell_type":"markdown","metadata":{},"source":["**Sugestão de Próximos Passos**\n","\n","1. Colocar para salvar o modelo com a menor validation loss.\n","2. Colocar código para carregar o modelo salvo e fazer predições em imagens do dataset.\n","3. Criar métricas de acurácia (Accuracy, Precision, Recall, F-score, etc.) para avaliar o dataset de teste com o modelo salvo.\n","\n","Quando tudo estiver pronto:\n","4. Criar novos modelos CNN (começar pela ResNet101).\n","5. Implementar outros modelos.\n","\n","Quando estiver pronto:\n","6. Implementar no seu dataset.\n"]},{"cell_type":"markdown","metadata":{},"source":["Para binário tem que mudar a loss (CrossEntropy), a sigmoid da layer final para softmax"]},{"cell_type":"markdown","metadata":{},"source":["# Materiais e Métodos\n","\n","## 1. Datasets\n","\n","Explicação sobre os conjuntos de dados utilizados.\n","\n","## 2. Modelos\n","\n","Explicação sobre como funciona um modelo CNN (Convolutional Neural Network) e os parâmetros utilizados.\n","\n","### 2.1. EfficientNet\n","\n","### 2.2. ResNet101\n","\n","...\n","\n","## 3. Métricas\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
