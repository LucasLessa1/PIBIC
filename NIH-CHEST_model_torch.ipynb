{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:05:11.118554Z","iopub.status.busy":"2022-01-02T01:05:11.117796Z","iopub.status.idle":"2022-01-02T01:05:13.680413Z","shell.execute_reply":"2022-01-02T01:05:13.679697Z","shell.execute_reply.started":"2022-01-02T01:05:11.118516Z"},"trusted":true},"outputs":[],"source":["import os  \n","import glob\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","import PIL \n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt \n","\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from efficientnet_pytorch import EfficientNet\n","from torchinfo import summary \n","\n","import torch.optim as optim\n","from IPython.display import Image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import transforms\n","import torch.nn.functional as F\n","\n","import pydicom\n","from PIL import Image\n","\n","import cv2"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:05:26.643276Z","iopub.status.busy":"2022-01-02T01:05:26.643017Z","iopub.status.idle":"2022-01-02T01:05:26.689544Z","shell.execute_reply":"2022-01-02T01:05:26.688904Z","shell.execute_reply.started":"2022-01-02T01:05:26.643247Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device "]},{"cell_type":"markdown","metadata":{},"source":["Set Random Seed for reproducability"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T01:07:17.417698Z","iopub.status.busy":"2022-01-02T01:07:17.417439Z","iopub.status.idle":"2022-01-02T01:07:17.425362Z","shell.execute_reply":"2022-01-02T01:07:17.424534Z","shell.execute_reply.started":"2022-01-02T01:07:17.417671Z"},"trusted":true},"outputs":[],"source":["random_seed = 124\n","np.random.seed(random_seed)\n","\n","torch.manual_seed(random_seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["train_df = pd.read_csv('C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/train_df.csv')\n","test_df = pd.read_csv('C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/test_df.csv')\n","valid_df = pd.read_csv('C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/valid_df.csv')"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["train_df = train_df[['Image Index', 'Finding Labels', 'Path Image']]\n","test_df = test_df[['Image Index', 'Finding Labels', 'Path Image']]\n","valid_df = valid_df[['Image Index', 'Finding Labels', 'Path Image']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"data":{"text/plain":["array(['No Finding'], dtype=object)"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["valid_df['Finding Labels'].unique()"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image Index</th>\n","      <th>Finding Labels</th>\n","      <th>Path Image</th>\n","      <th>testesteste</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00014396_000.png</td>\n","      <td>No Finding</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00025595_002.png</td>\n","      <td>No Finding</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00012520_003.png</td>\n","      <td>No Finding</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00001274_001.png</td>\n","      <td>No Finding</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00030596_000.png</td>\n","      <td>No Finding</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1495</th>\n","      <td>00013946_003.png</td>\n","      <td>No Finding</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>1496</th>\n","      <td>00000854_000.png</td>\n","      <td>No Finding</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>1497</th>\n","      <td>00029437_003.png</td>\n","      <td>No Finding</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>1498</th>\n","      <td>00016410_024.png</td>\n","      <td>No Finding</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>1499</th>\n","      <td>00028357_009.png</td>\n","      <td>No Finding</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1500 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["           Image Index Finding Labels  \\\n","0     00014396_000.png     No Finding   \n","1     00025595_002.png     No Finding   \n","2     00012520_003.png     No Finding   \n","3     00001274_001.png     No Finding   \n","4     00030596_000.png     No Finding   \n","...                ...            ...   \n","1495  00013946_003.png     No Finding   \n","1496  00000854_000.png     No Finding   \n","1497  00029437_003.png     No Finding   \n","1498  00016410_024.png     No Finding   \n","1499  00028357_009.png     No Finding   \n","\n","                                             Path Image  \\\n","0     C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...   \n","1     C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...   \n","2     C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...   \n","3     C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...   \n","4     C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...   \n","...                                                 ...   \n","1495  C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...   \n","1496  C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...   \n","1497  C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...   \n","1498  C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...   \n","1499  C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...   \n","\n","                              testesteste  \n","0     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n","1     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n","2     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n","3     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n","4     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n","...                                   ...  \n","1495  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n","1496  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n","1497  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n","1498  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n","1499  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n","\n","[1500 rows x 4 columns]"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["df = valid_df\n","\n","binary_labels = np.zeros((len(df), 7))\n","for i, row_label in enumerate(df['Finding Labels']):\n","    for j, label in enumerate(labels):\n","        if label == row_label:\n","            binary_labels[i][j] = 1\n","            \n","            \n","df['testesteste'] = list(binary_labels)\n","df"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"data":{"text/plain":["(1500, 7)"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["binary_labels.shape"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Length of values (31803) does not match length of index (1500)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Lucas\\PIBIC\\NIH-CHEST_model_torch.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y212sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m binary_labels\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y212sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m labels \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mNo Finding\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mInfiltration\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAtelectasis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEffusion\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNodule\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPneumothorax\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMass\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y212sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m valid_df[\u001b[39m'\u001b[39;49m\u001b[39mLabels\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(labels_to_binary(train_df, \u001b[39m'\u001b[39m\u001b[39mFinding Labels\u001b[39m\u001b[39m'\u001b[39m, labels))\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\core\\frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\core\\frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4136\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4149\u001b[0m     ):\n\u001b[0;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\core\\frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4870\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4871\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Length of values (31803) does not match length of index (1500)"]}],"source":["# Assuming df is your DataFrame and \"Finding Labels\" is your column with the labels\n","def labels_to_binary(df, labels_column, unique_labels):\n","    binary_labels = np.zeros((len(df), len(unique_labels)))\n","    for i, row_label in enumerate(df[labels_column]):\n","        for j, label in enumerate(unique_labels):\n","            if label == row_label:\n","                binary_labels[i][j] = 1\n","    return binary_labels\n","\n","labels = ['No Finding', 'Infiltration', 'Atelectasis', 'Effusion', 'Nodule', 'Pneumothorax', 'Mass']\n","valid_df['Labels'] = list(labels_to_binary(train_df, 'Finding Labels', labels))"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Length of values (31803) does not match length of index (1500)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Lucas\\PIBIC\\NIH-CHEST_model_torch.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y213sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_df[\u001b[39m'\u001b[39m\u001b[39mLabels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(labels_to_binary(train_df, \u001b[39m'\u001b[39m\u001b[39mFinding Labels\u001b[39m\u001b[39m'\u001b[39m, labels))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y213sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mLabels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(labels_to_binary(test_df, \u001b[39m'\u001b[39m\u001b[39mFinding Labels\u001b[39m\u001b[39m'\u001b[39m, labels))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y213sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m valid_df[\u001b[39m'\u001b[39;49m\u001b[39mLabels\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(labels_to_binary(train_df, \u001b[39m'\u001b[39m\u001b[39mFinding Labels\u001b[39m\u001b[39m'\u001b[39m, labels))\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\core\\frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\core\\frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4136\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4149\u001b[0m     ):\n\u001b[0;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\core\\frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4870\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4871\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Length of values (31803) does not match length of index (1500)"]}],"source":["train_df['Labels'] = list(labels_to_binary(train_df, 'Finding Labels', labels))\n","test_df['Labels'] = list(labels_to_binary(test_df, 'Finding Labels', labels))\n","valid_df['Labels'] = list(labels_to_binary(train_df, 'Finding Labels', labels))\n"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"'Labels'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","\u001b[1;31mKeyError\u001b[0m: 'Labels'","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Lucas\\PIBIC\\NIH-CHEST_model_torch.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_path, train_label \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(train_df[\u001b[39m'\u001b[39m\u001b[39mPath Image\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39mlist\u001b[39m(train_df[\u001b[39m'\u001b[39m\u001b[39mLabels\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y103sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_path, test_label \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(test_df[\u001b[39m'\u001b[39m\u001b[39mPath Image\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39mlist\u001b[39m(test_df[\u001b[39m'\u001b[39m\u001b[39mLabels\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y103sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m valid_path, valid_label \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(valid_df[\u001b[39m'\u001b[39m\u001b[39mPath Image\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39mlist\u001b[39m(valid_df[\u001b[39m'\u001b[39;49m\u001b[39mLabels\u001b[39;49m\u001b[39m'\u001b[39;49m])\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n","\u001b[1;31mKeyError\u001b[0m: 'Labels'"]}],"source":["train_path, train_label = list(train_df['Path Image']), list(train_df['Labels'])\n","test_path, test_label = list(test_df['Path Image']), list(test_df['Labels'])\n","valid_path, valid_label = list(valid_df['Path Image']), list(valid_df['Labels'])"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["7"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["len(['No Finding', 'Infiltration', 'Atelectasis', 'Effusion', 'Nodule', 'Pneumothorax', 'Mass'])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Define the labels and create a mapping from label to number\n","labels = ['No Finding', 'Infiltration', 'Atelectasis', 'Effusion', 'Nodule', 'Pneumothorax', 'Mass']\n","label_to_number = {label: i for i, label in enumerate(labels)}\n","\n","\n","\n","# Map the labels to numbers\n","train_label = [label_to_number[label] for label in train_label]\n","test_label = [label_to_number[label] for label in test_label]\n","valid_label = [label_to_number[label] for label in valid_label]"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image Index</th>\n","      <th>Finding Labels</th>\n","      <th>Path Image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00000005_006.png</td>\n","      <td>Infiltration</td>\n","      <td>C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Image Index Finding Labels  \\\n","0  00000005_006.png   Infiltration   \n","\n","                                          Path Image  \n","0  C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHE...  "]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head(1)"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset Class\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:06:32.906034Z","iopub.status.busy":"2022-01-02T02:06:32.905735Z","iopub.status.idle":"2022-01-02T02:06:32.915082Z","shell.execute_reply":"2022-01-02T02:06:32.914103Z","shell.execute_reply.started":"2022-01-02T02:06:32.906002Z"},"trusted":true},"outputs":[],"source":["class CT_Dataset(Dataset):\n","    def __init__(self, img_path, img_labels, img_transforms=None, grayscale=False):\n","        self.img_path = img_path\n","        self.img_labels = torch.Tensor(img_labels)\n","        if (img_transforms is None) & (grayscale == True):\n","            self.transforms = transforms.Compose([transforms.Grayscale(),\n","                                                  transforms.Resize((250, 250)),\n","                                                  transforms.ToTensor()])\n","        elif grayscale == False:\n","            self.transforms = transforms.Compose([transforms.Resize((250, 250)),\n","                                                  transforms.ToTensor()])\n","        else:\n","            self.transforms = img_transforms\n","    \n","    def __getitem__(self, index):\n","        # load image\n","        cur_path = self.img_path[index]\n","        cur_img = PIL.Image.open(cur_path).convert('RGB')\n","        cur_img = self.transforms(cur_img)\n","\n","        return cur_img, self.img_labels[index]\n","    \n","    def __len__(self):\n","        return len(self.img_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Model Development"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet50"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["\n","class ResNet50(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet50, self).__init__()\n","        self.resnet50 = models.resnet50(pretrained=True)\n","        in_features = self.resnet50.fc.in_features\n","        self.resnet50.fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.resnet50(x)\n"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet101"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["class ResNet101(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet101, self).__init__()\n","        self.resnet101 = models.resnet101(pretrained=True)\n","        in_features = self.resnet101.fc.in_features\n","        self.resnet101.fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.resnet101(x)"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB0"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["class EfficientNetB0(nn.Module):\n","    def __init__(self, num_classes):\n","        super(EfficientNetB0, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b0')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB4"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["class EfficientNetB4(nn.Module):\n","    def __init__(self, num_classes):\n","        super(EfficientNetB4, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b4')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n"]},{"cell_type":"markdown","metadata":{},"source":["### EfficientNetB7"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["class EfficientNetB7(nn.Module):\n","    def __init__(self, num_classes):\n","        super(EfficientNetB7, self).__init__()\n","        self.effnet = EfficientNet.from_pretrained('efficientnet-b7')\n","        in_features = self.effnet._fc.in_features\n","        self.effnet._fc = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.effnet(x)\n"]},{"cell_type":"markdown","metadata":{},"source":["### VGG16"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["class VGG16(nn.Module):\n","    def __init__(self, num_classes):\n","        super(VGG16, self).__init__()\n","        self.vgg16 = models.vgg16(pretrained=True)\n","        in_features = self.vgg16.classifier[6].in_features\n","        self.vgg16.classifier[6] = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.vgg16(x)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Function train_model"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["{'No Finding': 15000,\n"," 'Infiltration': 9547,\n"," 'Atelectasis': 4215,\n"," 'Effusion': 3955,\n"," 'Nodule': 2705,\n"," 'Pneumothorax': 2194,\n"," 'Mass': 2139}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["result_df = pd.read_csv('C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/result_df.csv')\n","qnt_labels = result_df['Finding Labels'].value_counts()\n","qnt_images_each_label = qnt_labels.to_dict()\n","qnt_images_each_label"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["total_samples = 0\n","for value in qnt_images_each_label.values():\n","    total_samples += value"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["9547"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["qnt_images_each_label['Infiltration']"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["[0.37861904761904763,\n"," 0.5948764757814721,\n"," 1.3473987459752583,\n"," 1.4359761603756547,\n"," 2.0995510958542383,\n"," 2.5885531970308633,\n"," 2.6551125358979495]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["labels = list(train_df['Finding Labels'].unique())\n","num_classes = len(train_df['Finding Labels'].unique())\n","\n","weight_No_Finding = total_samples/(qnt_images_each_label['No Finding'] * num_classes)\n","weight_Infiltration = total_samples/( qnt_images_each_label['Infiltration'] * num_classes)\n","weight_Atelectasis = total_samples/( qnt_images_each_label['Atelectasis'] * num_classes)\n","weight_Effusion = total_samples/( qnt_images_each_label['Effusion'] * num_classes)\n","weight_Nodule = total_samples/( qnt_images_each_label['Nodule'] * num_classes)\n","weight_Pneumothorax = total_samples/( qnt_images_each_label['Pneumothorax'] * num_classes)\n","weight_Mass = total_samples/( qnt_images_each_label['Mass'] * num_classes)\n","\n","weights = [weight_No_Finding, weight_Infiltration, weight_Atelectasis, weight_Effusion, weight_Nodule, weight_Pneumothorax, weight_Mass]\n","weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:38:15.316255Z","iopub.status.busy":"2022-01-02T02:38:15.315802Z","iopub.status.idle":"2022-01-02T02:38:15.333659Z","shell.execute_reply":"2022-01-02T02:38:15.332954Z","shell.execute_reply.started":"2022-01-02T02:38:15.316218Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","# Define the training function\n","def train_model(model, train_dataset, val_dataset, test_dataset, device, \n","                lr=0.0001, epochs=30, batch_size=32, l2=0.00001, gamma=0.5,\n","                patience=7):\n","    model = model.to(device)\n","\n","    # Construct dataloader\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    # History\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n","\n","    weight = torch.tensor(weights).to(device)\n","    \n","    # Set up loss function and optimizer\n","    criterion = nn.CrossEntropyLoss(weight=weight)  \n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=patience, gamma=gamma)\n","\n","    # Initialize variables to track the best validation loss and corresponding model state\n","    best_val_loss = float('inf')\n","    best_model_state = None\n","\n","    # Training Loop\n","    print(\"Training Start:\")\n","    for epoch in range(epochs):\n","        model.train()\n","\n","        train_loss = 0\n","        train_acc = 0\n","        val_loss = 0\n","        val_acc = 0\n","\n","        for i, (images, labels) in enumerate(train_loader):\n","            images = images.to(device)\n","            labels = labels.to(device).long()  # Convert labels to Long data type\n","\n","            outputs = model(images).float()  # Make sure the output is of type float\n","            pred = outputs.argmax(dim=1)\n","    \n","            cur_train_loss = criterion(outputs, labels)\n","            cur_train_acc = (pred == labels).sum().item() / batch_size\n","\n","            cur_train_loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            train_loss += cur_train_loss \n","            train_acc += cur_train_acc\n","        \n","        model.eval()\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images = images.to(device)\n","                labels = labels.to(device).long()  # Convert labels to Long data type\n","\n","                outputs = model(images).float()  # Make sure the output is of type float\n","\n","                cur_valid_loss = criterion(outputs, labels)\n","                val_loss += cur_valid_loss\n","\n","                pred = outputs.argmax(dim=1)\n","                val_acc += (pred == labels).sum().item() / batch_size\n","\n","        scheduler.step()\n","\n","        train_loss = train_loss / len(train_loader)\n","        train_acc = train_acc / len(train_loader)\n","        val_loss = val_loss / len(val_loader)\n","        val_acc = val_acc / len(val_loader)\n","\n","        print(f\"Epoch:{epoch + 1} / {epochs}, lr: {optimizer.param_groups[0]['lr']:.5f} train loss:{train_loss:.5f}, train acc: {train_acc:.5f}, valid loss:{val_loss:.5f}, valid acc:{val_acc:.5f}\")\n","    \n","        history['train_loss'].append(train_loss)\n","        history['train_acc'].append(train_acc)\n","        history['val_loss'].append(val_loss)\n","        history['val_acc'].append(val_acc)\n","    \n","        # Update the best model if validation loss is the lowest so far\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            best_model_state = model.state_dict()\n","\n","    # Load the best model state\n","    if best_model_state is not None:\n","        model.load_state_dict(best_model_state)\n","\n","    test_acc = 0\n","    print(f'The best val loss is {best_val_loss}.\\n\\n')\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device).long()  # Convert labels to Long data type\n","\n","            outputs = model(images).float()  # Make sure the output is of type float\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predictions)\n","            pred = outputs.argmax(dim=1)\n","            test_acc += (pred == labels).sum().item()\n","            print(y_true)\n","            print(y_pred)\n","\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","    \n","    print(f'Test Accuracy:  {(test_acc / len(test_loader))}')\n","\n","    return history, model\n"]},{"cell_type":"markdown","metadata":{},"source":["Process the datasets and train the model"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Current GPU memory usage: 0.0 MB\n","Max GPU memory usage: 0.0 MB\n"]}],"source":["print(\"Current GPU memory usage:\", torch.cuda.memory_allocated() / (1024 ** 2), \"MB\")\n","print(\"Max GPU memory usage:\", torch.cuda.max_memory_allocated() / (1024 ** 2), \"MB\")\n","\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["(31803, 31803)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["len(train_path), len(train_label)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["train_dataset = CT_Dataset(img_path=train_path, img_labels=np.array(train_label))\n","val_dataset = CT_Dataset(img_path=valid_path, img_labels=np.array(valid_label))\n","test_dataset = CT_Dataset(img_path=test_path, img_labels=np.array(test_label))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model_resnet50 = ResNet50(num_classes=7)\n","# train_loader = train_model(model_resnet50, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["23035dfbdfbdb"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-01-02T02:40:25.322238Z","iopub.status.busy":"2022-01-02T02:40:25.321990Z","iopub.status.idle":"2022-01-02T02:42:57.004380Z","shell.execute_reply":"2022-01-02T02:42:57.003631Z","shell.execute_reply.started":"2022-01-02T02:40:25.322210Z"},"trusted":true},"outputs":[],"source":["batch_size = 32\n","epoch = 10\n","label_model = \"ResNet50_\"\n","path_save_model = f'C:/Users/Lucas/Documents/PIBIC/DATASET/NIH-CHEST/model_/{label_model}{epoch}'\n","# Train the ResNet101 model\n","model_resnet50 = ResNet50(num_classes=7)\n","hist_ResNet50, model_ResNet50 = train_model(model_resnet50, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)\n","\n","\n","# # Train the ResNet101 model\n","# model_resnet101 = ResNet101(num_classes=7)\n","# hist_ResNet101, model_ResNet101 = train_model(model_resnet101, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)\n","\n","\n","# Train the EfficientNetB0 model\n","# model_efficientnet_b0 = EfficientNetB\n","# \n","# 333333333333333333333320(num_classes=7)\n","# hist_EfficientNetB0, model_EfficientNetB0 = train_model(model_efficientnet_b0, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)\n","\n","\n","# Train the EfficientNetB4 model\n","# model_efficientnet_b4 = EfficientNetB4(num_classes=7)\n","# hist_EfficientNetB4, model_EfficientNetB4 = train_model(model_efficientnet_b4, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)\n","\n","\n","# # Train the EfficientNetB7 model\n","# model_efficientnet_b7 = EfficientNetB7(num_classes=7)\n","# hist_EfficientNetB7, model_EfficientNetB7 = train_model(model_efficientnet_b7, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)\n","\n","\n","# # Train the VGG16 model\n","# model_vgg16 = VGG16(num_classes=7)\n","# hist_VGG16, model_VGG16 = train_model(model_vgg16, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size= batch_size, epochs=epoch, l2=0.09, patience=5)model_vgg16 "]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["hist_kernel = hist_ResNet50\n","model_kernel = model_ResNet50\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["torch.save(model_resnet50.state_dict(), f'{path_save_model}.pth')"]},{"cell_type":"markdown","metadata":{},"source":["## Metricis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_metrics(hist, label_model) :\n","    # plot training curves\n","    epochs = range(1, len(hist['train_loss']) + 1)\n","\n","    train_loss = [t.cpu().detach().numpy() for t in hist['train_loss']]\n","    val_loss = [t.cpu().detach().numpy() for t in hist['val_loss']]\n","\n","\n","    fig, ax = plt.subplots(1,2, figsize=(20,6))\n","    ax[0].plot(epochs, train_loss, 'r-', label='Train')\n","    ax[0].plot(epochs, val_loss, 'b-', label='Evaluation')\n","    ax[0].set_title('Loss')\n","    ax[0].set_xlabel('Epochs')\n","    ax[0].set_ylabel('Loss')\n","    ax[0].legend()\n","    plt.savefig(f'{path_save_model}.png')  # This saves the plot as a PNG image\n","\n","    ax[1].plot(epochs, hist['train_acc'], 'r-', label='Train')\n","    ax[1].plot(epochs, hist['val_acc'], 'b-', label='Evaluation')\n","    ax[1].set_title('Accuracy')\n","    ax[1].set_xlabel('Epochs')\n","    ax[1].set_ylabel('Acc')\n","    ax[1].legend()\n","    plt.savefig(f'{path_save_model}.png')  # This saves the plot as a PNG image\n","    \n","\n","    plt.show()\n","    \n","    \n","plot_metrics(hist_kernel, label_model)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["def calculate_metrics(model, test_dataset, device, plot_images=False):\n","    # Initialize variables to store predictions and ground truth\n","    y_true = []\n","    y_pred = []\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    cont = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predictions)\n","            cont+=1\n","            if cont == 5:\n","                break\n","\n","    # Convert lists to numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","\n","    return y_true, y_pred\n","\n","\n","\n","y_true, y_pred = calculate_metrics(model_kernel, test_dataset, device, plot_images=True)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["from sklearn.metrics import multilabel_confusion_matrix, precision_score, accuracy_score, recall_score, f1_score\n"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/plain":["(array([1., 1., 1., 1., 1.], dtype=float32),\n"," array([[0., 0., 1., 1., 0., 1., 1.],\n","        [0., 0., 1., 1., 0., 0., 1.],\n","        [0., 0., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 0., 1., 1.],\n","        [0., 0., 1., 1., 0., 0., 1.]], dtype=float32))"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["y_true, y_pred"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Classification metrics can't handle a mix of binary and multilabel-indicator targets","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Lucas\\PIBIC\\NIH-CHEST_model_torch.ipynb Cell 46\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y210sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cm_matrix \u001b[39m=\u001b[39m confusion_matrix(y_true, y_pred)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\metrics\\_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m    232\u001b[0m     {\n\u001b[0;32m    233\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m ):\n\u001b[0;32m    244\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    328\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n","\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"]}],"source":["cm_matrix = confusion_matrix(y_true, y_pred)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Classification metrics can't handle a mix of binary and multilabel-indicator targets","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Lucas\\PIBIC\\NIH-CHEST_model_torch.ipynb Cell 46\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y204sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calculate evaluation metrics\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y204sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cm_matrix \u001b[39m=\u001b[39m multilabel_confusion_matrix(y_true, y_pred)\u001b[39m.\u001b[39mravel()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y204sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m precision \u001b[39m=\u001b[39m precision_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#Y204sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_true, y_pred)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\metrics\\_classification.py:505\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[1;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m    396\u001b[0m     {\n\u001b[0;32m    397\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    406\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, samplewise\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    407\u001b[0m ):\n\u001b[0;32m    408\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute a confusion matrix for each class or sample.\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \n\u001b[0;32m    410\u001b[0m \u001b[39m    .. versionadded:: 0.21\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[39m            [1, 2]]])\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 505\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    506\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m         sample_weight \u001b[39m=\u001b[39m column_or_1d(sample_weight)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n","\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"]}],"source":["# Calculate evaluation metrics\n","cm_matrix = multilabel_confusion_matrix(y_true, y_pred).ravel()\n","precision = precision_score(y_true, y_pred, average='weighted')\n","accuracy = accuracy_score(y_true, y_pred)\n","recall = recall_score(y_true, y_pred, average='weighted')\n","f1 = f1_score(y_true, y_pred, average='weighted')\n","specificity = tn / (tn + fp)\n","sensitivity = tp / (fn + tp)\n","\n","metrics = {\n","    'precision': precision,\n","    'recall': recall,\n","    'f1_score': f1,\n","    'accuracy': accuracy,\n","    'specificity': specificity,\n","    'sensitivity': sensitivity,\n","    'false negativo': fn\n","}\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","c:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"ename":"ValueError","evalue":"Classification metrics can't handle a mix of binary and multilabel-indicator targets","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Lucas\\PIBIC\\NIH-CHEST_model_torch.ipynb Cell 44\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X56sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m model_kernel\u001b[39m.\u001b[39meval()  \u001b[39m# Set the model to evaluation mode\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X56sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m# Call the function with plot_images=True to plot images\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X56sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m metrics \u001b[39m=\u001b[39m calculate_metrics(model_kernel, test_dataset, device, plot_images\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X56sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m metrics\n","\u001b[1;32mc:\\Users\\Lucas\\PIBIC\\NIH-CHEST_model_torch.ipynb Cell 44\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X56sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X56sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Calculate evaluation metrics\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X56sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m cm \u001b[39m=\u001b[39m multilabel_confusion_matrix(y_true, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X56sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m precision \u001b[39m=\u001b[39m precision_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/PIBIC/NIH-CHEST_model_torch.ipynb#X56sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_true, y_pred)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\metrics\\_classification.py:505\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[1;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m    396\u001b[0m     {\n\u001b[0;32m    397\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    406\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, samplewise\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    407\u001b[0m ):\n\u001b[0;32m    408\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute a confusion matrix for each class or sample.\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \n\u001b[0;32m    410\u001b[0m \u001b[39m    .. versionadded:: 0.21\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[39m            [1, 2]]])\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 505\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    506\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m         sample_weight \u001b[39m=\u001b[39m column_or_1d(sample_weight)\n","File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\torch000\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n","\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"]}],"source":["def calculate_metrics(model, test_dataset, device, plot_images=False):\n","    # Initialize variables to store predictions and ground truth\n","    y_true = []\n","    y_pred = []\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    cont = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predictions)\n","            cont+=1\n","            if cont == 5:\n","                break\n","\n","    # Convert lists to numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","    # Calculate evaluation metrics\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    accuracy = accuracy_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","    specificity = tn / (tn + fp)\n","    sensitivity = tp / (fn + tp)\n","\n","    metrics = {\n","        'precision': precision,\n","        'recall': recall,\n","        'f1_score': f1,\n","        'accuracy': accuracy,\n","        'specificity': specificity,\n","        'sensitivity': sensitivity,\n","        'false negativo': fn\n","    }\n","\n","    return metrics\n","\n","\n","\n","model_path = f'{path_save_model}.pth'\n","\n","if label_model[:7] == \"ResNet1\":\n","    model_kernel = ResNet101(num_classes=7)\n","\n","elif label_model[:7] == \"ResNet5\":\n","    model_kernel = ResNet50(num_classes=7)\n","\n","elif label_model[:14] == \"EfficientNetB0\":\n","    model_kernel = EfficientNetB0(num_classes=7)\n","    \n","elif label_model[:14] == \"EfficientNetB4\":\n","    model_kernel = EfficientNetB4(num_classes=7)\n","\n","elif label_model[:14] == \"EfficientNetB7\":\n","    model_kernel = EfficientNetB7(num_classes=7)\n","\n","elif label_model[:5] == \"VGG16\":\n","    model_kernel = VGG16(num_classes=7)\n","\n","\n","model_kernel.load_state_dict(torch.load(model_path))\n","model_kernel.to(device)  # Move the model to the specified device\n","model_kernel.eval()  # Set the model to evaluation mode\n","\n","# Call the function with plot_images=True to plot images\n","metrics = calculate_metrics(model_kernel, test_dataset, device, plot_images=True)\n","metrics"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["array([[[3, 1],\n","        [0, 2]],\n","\n","       [[5, 0],\n","        [1, 0]],\n","\n","       [[2, 1],\n","        [1, 2]]], dtype=int64)"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n","y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n","multilabel_confusion_matrix(y_true, y_pred)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.DataFrame(metrics.items(), columns=['Metric', 'Value']).to_csv(f'{path_save_model}.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_images(model, test_dataset, device, plot_images=False, num_images_to_plot=10):\n","    # Initialize variables to store predictions and ground truth\n","    y_pred = []\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","    images_plotted = 0  # Counter for the number of images plotted\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            predictions = torch.round(torch.sigmoid(outputs)).cpu().numpy()\n","            y_pred.extend(predictions)\n","\n","            # Plot images with true and predicted labels\n","            if plot_images and images_plotted < num_images_to_plot:\n","                plot_image(images, labels, predictions)\n","                images_plotted += 1\n","\n","            # Break the loop if the desired number of images is plotted\n","            if images_plotted >= num_images_to_plot:\n","                break\n","\n","\n","def plot_image(images, true_label, predicted_label):\n","    if len(images.shape) == 4 and images.shape[1] == 3:\n","        # Convert CUDA tensor to numpy array and rearrange dimensions for RGB image\n","        images = images.cpu().detach().numpy().squeeze().transpose((1, 2, 0))\n","    else:\n","        # Convert CUDA tensor to numpy array and squeeze if necessary\n","        images = images.cpu().detach().numpy().squeeze()\n","\n","    if len(images.shape) == 2:\n","        plt.imshow(images, cmap='gray')\n","    else:\n","        plt.imshow(images)\n","    \n","    # Format the labels\n","    true_label = true_label.item() if isinstance(true_label, torch.Tensor) else true_label\n","    predicted_label = predicted_label.item() if isinstance(predicted_label, torch.Tensor) else predicted_label\n","    \n","    plt.title(f'True label: {true_label}; Predicted: {predicted_label}')\n","    plt.show()\n","    \n","    \n","process_images(model_kernel, test_dataset, device, plot_images=True)"]},{"cell_type":"markdown","metadata":{},"source":["**SugestÃ£o de PrÃ³ximos Passos**\n","\n","1. Colocar para salvar o modelo com a menor validation loss.\n","2. Colocar cÃ³digo para carregar o modelo salvo e fazer prediÃ§Ãµes em imagens do dataset.\n","3. Criar mÃ©tricas de acurÃ¡cia (Accuracy, Precision, Recall, F-score, etc.) para avaliar o dataset de teste com o modelo salvo.\n","\n","Quando tudo estiver pronto:\n","4. Criar novos modelos CNN (comeÃ§ar pela ResNet101).\n","5. Implementar outros modelos.\n","\n","Quando estiver pronto:\n","6. Implementar no seu dataset.\n"]},{"cell_type":"markdown","metadata":{},"source":["Para binÃ¡rio tem que mudar a loss (CrossEntropy), a sigmoid da layer final para softmax"]},{"cell_type":"markdown","metadata":{},"source":["# Materiais e MÃ©todos\n","\n","## 1. Datasets\n","\n","ExplicaÃ§Ã£o sobre os conjuntos de dados utilizados.\n","\n","## 2. Modelos\n","\n","ExplicaÃ§Ã£o sobre como funciona um modelo CNN (Convolutional Neural Network) e os parÃ¢metros utilizados.\n","\n","### 2.1. EfficientNet\n","\n","### 2.2. ResNet101\n","\n","...\n","\n","## 3. MÃ©tricas\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
